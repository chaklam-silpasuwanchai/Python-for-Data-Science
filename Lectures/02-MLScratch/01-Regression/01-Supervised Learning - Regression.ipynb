{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Supervised Learning - Regression\n",
    "\n",
    "### Readings: \n",
    "- [GERON] Ch4\n",
    "- [VANDER] Ch5\n",
    "- [HASTIE] Ch3\n",
    "- https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Regression is a supervised algorithm to make prediction based on continous y values.  \n",
    "\n",
    "For example, given the following data:\n",
    "\n",
    "| | Egg price  | Gold price    | Oil price   | GDP   |\n",
    "|---:|:-------------|:-----------|:------|:------|\n",
    "| 1 | 3  | 100       | 4   | 21   |\n",
    "| 2 | 4  | 500    | 7   | 43     |\n",
    "\n",
    "We want to use egg price, gold price and oil price to predict GDP.  We called egg price, gold price, oil price **features**. We called what we want to predict **labels** or **targets**.  Each row is called **sample**.  \n",
    "\n",
    "#### Course Notations and Terms\n",
    "\n",
    "*This is important.  Although we are only talking only about linear regression, most of these notations and terms applied to other algorithms as well.*\n",
    "\n",
    "To make our life easier later, we shall use the following notations throughout our course.  $x_j^{(i)}$ is used to represent the i-th sample, and j-th feature. For example, $x_1^{(1)}$ denote egg price of the first sample (i.e., 100), $x_2^{(1)}$ for gold price of the first sample (i.e., 4), and $x_3^{(1)}$ for oil price of the first sample (i.e., 21).  We use bold captial $X$ to denote the whole matrix of features with $m$ rows of samples and $n$ columns of features.  For compliance to python, we shall called that the **shape** of $X$ as $(m, n)$.  We use $y^{(i)}$ to represent the targets/labels of the i-th sample, where when we do not specify the $i$, i.e., $y$ refers to the whole vector of targets with shape of $(m, )$\n",
    "\n",
    "We shall define **hypothesis function** as function which given input $X$, will output the predicted $y$.  In machine learning algorithms, we must **learn** and **train** this function to output predicted y as close to actual y.  To differentiate between actual and predicted $y$, we commonly called predicted $y$ as $\\hat{y}$ (read as yhat)\n",
    "\n",
    "For linear regression, the hypothesis function (denoted as $h_{\\theta}(x)$ which means $h$ depends on $x$ parametize by $\\theta$) is defined as followed.  \n",
    "\n",
    "\\begin{align*}\n",
    "h_\\theta(x) &= \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\cdots + \\theta_nx_n \\tag{A}\\\\\n",
    "&= \\sum_{i=0}^n \\theta_ix_i  \\tag{B}\\\\\n",
    "&= \\boldsymbol{\\theta}^T \\mathbf{x} \\tag{C}\n",
    "\\end{align*}\n",
    "\n",
    "Here $\\theta$ are called **parameters** or **weights** or **coefficients** that parameterize the linear mappings from $X$ -> $y$.  Also, we commonly don't write equations in the (A) form.  We called (B) form as the summation form and (C) as the **vectorized** form.  Since vectorized form resemble closely to python programming and will make our code clean without many for loops, this course will write in vectorized form when possible.  Note that in equation B, to be mathematically correct, we make $x_0 = 1$ for the intercept term.\n",
    "\n",
    "We shall further define a **training** set which is subset of the whole dataset used to **train** the hypothesis function so that it can accurately predict $y$.  The resulting hypothesis function is called **model**.  We also shall define a **testing** set which is also a subset of the whole dataset used to **test** the score of the model.  The common practice is to split $70/80\\%$ for training set and $30/20\\%$ for testing set.\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "As you can probably realize, training here refers to training the $\\theta$.  How do we pick or learn the paremeters $\\theta$?  One reasonable way is to make $h_\\theta(x)$ close to $y$, at least for the training examples we have.  To formalize this, we shall define a function that measures, for a given $\\theta$, how close the $h(x^{(i)})$ are to the corresponding $y^{(i)}$.  We called this function the **cost function** or **loss function** (denoted as $J$):\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "We want to choose $\\theta$ so as to minimize $J(\\theta)$.  Such minimization problem will be generally called as **optimization problems**.  Any solution that can help us find the optimal values is called **optimization algorithms**.  Commonly, in such optimization problem, we starts with some random values for $\\theta$ (e.g., zeros), and then repeatedly changes $\\theta$ to make $J(\\theta)$ smaller, until hopefully we converge to a value of $\\theta$ that minimizes $J(\\theta)$.  \n",
    "\n",
    "One such optimization algorithm to do that is called **gradient descent** algorithm, which starts with some initial $\\theta$, and repeatedly performs the update:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    " \n",
    "This update is simultaneously performed for all values of $j=0, 1, \\cdots, n$.  Here, $\\alpha$ is called the **learning rate**, ranging from 0 to 1.  Commonly, we tried 0.001 as default, and this value must be **fine-tuned** in order to know what value is the best.  Any parameters such as learning rate that we need to fine-tuned through trial and errors are called **hyperparameters**.\n",
    "\n",
    "In order to implement this algorithm, we have to find the **partial derivative of the loss function in respect to each $\\theta_j$**.  Let's try the partial derivative of our loss function in respect to $\\theta_j$.  Also, let's first work it out for only one training example first as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial \\theta_j} &= \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}(h_\\theta(x) - y)^2 \\\\\n",
    "&= 2 * \\frac{1}{2} (h_\\theta(x) - y) * \\frac{\\partial}{\\partial \\theta_j} (h_\\theta(x) - y) \\\\\n",
    "&= 2 * \\frac{1}{2} (h_\\theta(x) - y) * \\frac{\\partial}{\\partial \\theta_j} \\big(\\sum_{i=0}^n \\theta_ix_i - y\\big) \\\\\n",
    "&= (h_\\theta(x) - y)x_j\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This rule has several properties that seem natural and intuitive. For instance, the magnitude of the update is proportional to the **error** term $h_\\theta(x) - y$; thus, for instance, if we are encountering a training example on which our prediction nearly matches the actual value of $y^{(i)}$, then we find that there is little need to change the parameters; in contrast, a larger change to the parameters will be made if our prediction has a large error (i.e., if it is very far from $y^{(i)}$).\n",
    "\n",
    "To modify the update rule for whole training example, we revise the update rule to include the summation as\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\tag{for every $j$}$$\n",
    "\n",
    "Notice that minus sign which indicates **gradient descent**.  We can simply flip the sign to plus and called it as **gradient ascent**, both of which give the same answer.\n",
    "\n",
    "$$\\theta_j := \\theta_j + \\alpha \\sum_{i=1}^m(y^{(i)} - h_\\theta(x^{(i)}))x_j^{(i)} \\tag{for every $j$}$$\n",
    "\n",
    "Since this gradient descent calculates gradient using every example in the entire training set, we called this as **batch gradient descent**.\n",
    "\n",
    "Sometimes, performing batch gradient descent can be slow, thus we can use **stochastic gradient descent** which refers to looking at only one training example, where we can pick with or without replacement.  Here, **without replacement** refers to the process in which no same sample is used in the same **epoch**.  Here epoch means one  iteration which the whole training set is being exhausted.  Thus, in without replacement, we simply loop from $i =1$ to $m$ for one epoch.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha ((h_\\theta(x)^{(i)}-y^{(i)})x_j^{(i)}) \\tag{for every $j$}$$\n",
    "\n",
    "Although **stochastic gradient descent** may be faster, it rarely converges to the optimum given its randomness.  A middle ground is **mini-batch gradient descent** which can be expressed as\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\sum_{i=start}^{batchsize}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\tag{for every $j$}$$\n",
    "\n",
    "Similarly, we can do this with or without replacement.  In without replacement, we simply chop evenly and exhaust the whole training set for one epoch.\n",
    "\n",
    "#### Closed form\n",
    "\n",
    "Gradient descent gives one possible mean for minimizing $J$, which uses iterative approach and may take time.  In the situation where we know that our cost function is strictly concave or convex, we can explicitly take its derivative to zero.  This process of derivation is called obtaining the **normal equations** or **closed form**. \n",
    "\n",
    "The **closed form** of linear regression can be derived easily.  Let $\\mathbf{X}$ be a matrix of shape $(m, n)$, $\\boldsymbol{\\theta}$ as shape $(n, )$, and $\\mathbf{y}$ as vector of shape $(m, )$.  Instead of writing the cost function as power of square, we shall write it in matrix multiplication as follows:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\boldsymbol{\\theta}} (\\mathbf{X}\n",
    " - \\mathbf{y})^T*(\\mathbf{X}\n",
    "-\\mathbf{y})$$\n",
    "\n",
    "Recall the following properties:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{X}} \\mathbf{X}^T\\mathbf{X}=2\\mathbf{X} \\tag{A}$$\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{X}} \\mathbf{A}\\mathbf{X}=\\mathbf{A}^T$$\n",
    "$$(\\mathbf{X}\\mathbf{y})^T = \\mathbf{y}^T\\mathbf{X}^T$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial \\boldsymbol{\\theta}} (\\mathbf{X}\\boldsymbol{\\theta} - \\mathbf{y})^T*(\\mathbf{X}\\boldsymbol{\\theta}-\\mathbf{y}) &= \\frac{\\partial J}{\\partial \\boldsymbol{\\theta}} (\\boldsymbol{\\theta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\theta} - \\boldsymbol{\\theta}^T\\mathbf{X}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\theta} + \\mathbf{y}^T\\mathbf{y})\\\\\n",
    "&= 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\theta} - 2\\mathbf{X}^T\\mathbf{y} \\tag{see note*}\\\\\n",
    "&= \\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\theta} - \\mathbf{X}^T\\mathbf{y} = 0 \\tag{set derivative to 0}\\\\\n",
    "&= \\boldsymbol{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Note*: Since $\\mathbf{X}\\boldsymbol{\\theta}$ is a vector, and so is $\\mathbf{y}$, it doesn't matter what the order is, thus we can simply add them to 2.  Also, we got 2 in front of the first part because we have two $\\theta$ (used the property A)\n",
    "\n",
    "\n",
    "**Why not closed form always**.  The answer is simple.  It does not always exists or possible, for example, the cost function is not convex or concave.  But of course, if it exists, we usually prefer closed form given that it is usually faster than gradient descent.  Nevertheless, as you can see, taking inverse of huge number of features can be expensive, thus it is also not always straightforward thing to always prefer closed form.\n",
    "\n",
    "Yes, that's it for most of the theoretical stuff.  Let's start implementing some of these concepts so we can better understand them.\n",
    "\n",
    "After we implement them from scratch, we shall explore them further using sklearn which will save us a lot of time from implementing from scratch and also comes with a lot of nice utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Closed Form\n",
    "\n",
    "The closed form is a normal equations derived from setting the derivatives = 0.  By performing only some inverse operations and matrix multiplication, we will be able to get the theta.\n",
    "\n",
    "$$\\boldsymbol{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "When closed form is available, is doable (can be inversed - can use pseudoinverse), and with not many features (i.e., inverse can be slow), it is recommended to always use closed form.  \n",
    "\n",
    "**Implementation steps:**\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "        - where $m$ is number of samples\n",
    "        - where $n$ is number of features\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Plug everything into the equation.  Here we shall use X_train to retrieve the $\\boldsymbol{\\theta}$\n",
    "$$\\boldsymbol{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "3. We simply using the $\\boldsymbol{\\theta}$, we can perform a dot product with our X_test which will give us $\\mathbf{\\hat{y}}$.\n",
    "\n",
    "4. We then calculate the errors using mean-squared-error function:\n",
    "\n",
    "$$\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "Note that it's a bit different from our $J(\\boldsymbol{\\theta})$ because $J(\\boldsymbol{\\theta})$ puts $\\frac{1}{2}$ instead of $\\frac{1}{m}$ for mathematical convenience for derivatives, since we know changing constants do not change the optimization results.\n",
    "\n",
    "\n",
    "#### 1.1 Get your X and y in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's load some boston data \n",
    "# as our regression case study\n",
    "from sklearn.datasets import load_boston\n",
    "# type - Bunch\n",
    "# Bunch - dictionary of numpy data\n",
    "# boston.feature_names\n",
    "# print(boston)\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "X.shape #number of samples, number of features\n",
    "\n",
    "m = X.shape[0]  #number of samples\n",
    "n = X.shape[1]  #number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in X is the same as number of rows in y\n",
    "# because so we have yhat for all y\n",
    "assert m == y.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Feature scale your data to reach faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to standardize my data so that mean is 0, variance is 1\n",
    "# average across each feature, NOT across each sample\n",
    "# Why we need to standardize\n",
    "# Because standardizing usually allows us to reach convergence faster\n",
    "# Why -> because the values are within smaller range\n",
    "# Thus, the gradients are also within limited range, and NOT go crazy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. StandardScaler.fit(X)  #this scaler (or self) knows the mean and std so now\n",
    "# it knows how to transform data\n",
    "# 2  X = StandardScaler.transform(X)  #not in place; will return something\n",
    "\n",
    "# 1. StandardScaler.fit_transform(X) -> 1 and 2 sequentially\n",
    "\n",
    "# create an object of StandardScaler\n",
    "# StandardScaler is a class\n",
    "# scaler is called instance/object\n",
    "\n",
    "# ALMOST always, feature scale your data using normalization or standardization\n",
    "# If you assume your data is gaussian, use standardization, otherwise, you do the normalization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Train test split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the appropriate size for test data\n",
    "# 70/30 (small dataset); 80/20 (medium dataset); 90/10 (large dataset);\n",
    "# why large dataset, can set test size to 10, because\n",
    "# 10% of large dataset is already enough for testing accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "assert len(X_train)  == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Add intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of X they want\n",
    "# (number of samples, number of features) --> correct shape\n",
    "# for closed form formula\n",
    "# How about the intercept\n",
    "# w0 is OUR intercept\n",
    "# what is the shape of w -->(n+1, )\n",
    "# What is the shape of intercept --->(m, 1)\n",
    "#X = [1 2 3     @  [w0\n",
    "#     1 4 6         w1\n",
    "#     1 9 1         w2 \n",
    "#     1 10 2 ] \n",
    "\n",
    "# np.ones((shape))\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "\n",
    "# concatenate the intercept based on axis=1\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)\n",
    "\n",
    "# np.ones((shape))\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "\n",
    "# concatenate the intercept based on axis=1\n",
    "X_test = np.concatenate((intercept, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Feature Engineering (optional)\n",
    "\n",
    "It is sometimes useful to engineer new features (e.g., polynomial, kernels) so to create some non-linear relationships with your target.\n",
    "\n",
    "Here we gonna skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit your algorithm \n",
    "\n",
    "#### 1. Define your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "# order of operation DOES NOT MATTER\n",
    "# But don't flip y before X^T for example\n",
    "def closed_form(X, y):\n",
    "    return inv(X.T @ X) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25860429e+01, -9.31959893e-01,  1.15022934e+00,  1.67895103e-01,\n",
       "        7.74252033e-01, -2.34006186e+00,  2.02772542e+00, -1.83777607e-02,\n",
       "       -3.52881939e+00,  3.12871992e+00, -2.35482866e+00, -2.01528424e+00,\n",
       "        9.39115715e-01, -3.99583047e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the closed_form to find the theta\n",
    "theta = closed_form(X_train, y_train)\n",
    "theta  #<------this is our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy/loss\n",
    "\n",
    "yhat = X_test @ theta #==> X (m, n+1)  @ (n+1, ) w ==> (m, ) y\n",
    "\n",
    "# if I want to compare yhat and y, I need to make sure they are the same shape\n",
    "assert y_test.shape == yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared errors:  23.406961422718172\n"
     ]
    }
   ],
   "source": [
    "# get the mse\n",
    "mse = ((y_test - yhat)**2).sum() / X_test.shape[0]\n",
    "print(\"Mean squared errors: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2: Batch Gradient Descent\n",
    "\n",
    "The gradient descent has the following steps:\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict and calculate the loss\n",
    "    - The loss function is the mean squared error\n",
    "    $$J = \\frac{ \\sum_{i=1}^{m} (h-y)^2}{2}$$\n",
    "    where $h$ is simply\n",
    "    $$ h = \\boldsymbol{\\theta}^Tx $$\n",
    "3. Calculate the gradient based on the loss\n",
    "    - The gradient of the loss function is\n",
    "    $$\\frac{\\partial J}{\\partial \\theta_j} = \\sum_{i=1}^{m}(h^{(i)}-y^{(i)})x_j$$\n",
    "4. Update the theta with this update rule\n",
    "    $$\\theta_j := \\theta_j - \\alpha * \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    "    where $\\alpha$ is a typical learning rate range between 0 and 1\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Step 1: Prepare your data\n",
    "# X_train, X_test have intercepts that are being concatenated to the data\n",
    "# [1, features\n",
    "#  1, features....]\n",
    "\n",
    "# making sure our X_train has same sample size as y_train\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "\n",
    "# initialize our w\n",
    "# We don't have to do X.shape[1] + 1 because our X_train already has the\n",
    "# intercept\n",
    "# w = theta/beta/coefficients\n",
    "theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "# define the learning rate\n",
    "# later on, you gonna know that it should be better to make it slowly decreasing\n",
    "# once we perform a lot of iterations, we want the update to slow down, so it converges better\n",
    "alpha = 0.0001\n",
    "\n",
    "# define our max_iter\n",
    "# typical to call it epochs <---ml people likes to call it\n",
    "max_iter = 1000\n",
    "\n",
    "loss_old = 10000\n",
    "\n",
    "tol = 0.0001\n",
    "\n",
    "iter_stop = 0\n",
    "\n",
    "def h_theta(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def mse(yhat, y):\n",
    "    return ((yhat - y)**2).sum() / yhat.shape[0]\n",
    "\n",
    "def gradient(X, error):\n",
    "    return X.T @ error\n",
    "\n",
    "start = time()\n",
    "\n",
    "# define your for loop\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    # 1. yhat = X @ w\n",
    "    # prediction\n",
    "    # yhat (m, ) = (m, n) @ (n, )\n",
    "    yhat = h_theta(X_train, theta)\n",
    "\n",
    "    # 2. error = yhat - y_train\n",
    "    # error for use to calculate gradients\n",
    "    # error (m, ) = (m, ) - (m, )\n",
    "    error = yhat - y_train\n",
    "\n",
    "    # 3. grad = X.T @ error\n",
    "    # grad (n, ) = (n, m) @ (m, )\n",
    "    # grad for each feature j\n",
    "    grad = gradient(X_train, error)\n",
    "\n",
    "    # 4. w = w - alpha * grad\n",
    "    # update w\n",
    "    # w (n, ) = (n, ) - scalar * (n, )\n",
    "    theta = theta - alpha * grad\n",
    "\n",
    "time_taken = time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  23.288128316865823\n",
      "Stop at iteration:  839\n",
      "Time used:  0.02283024787902832\n"
     ]
    }
   ],
   "source": [
    "# we got our lovely w\n",
    "# now it's time to check our accuracy\n",
    "# 1. Make prediction\n",
    "yhat = h_theta(X_test, theta)\n",
    "\n",
    "# 2. Calculate mean squared errors\n",
    "mse = mse(yhat, y_test)\n",
    "\n",
    "# print the mse\n",
    "print(\"MSE: \", mse)\n",
    "print(\"Stop at iteration: \", iter_stop)\n",
    "print(\"Time used: \", time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Stochastic Gradient Descent\n",
    "\n",
    "The gradient descent has the following steps:\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict and calculate the loss\n",
    "3. Calculate the gradient based on the loss\n",
    "    - **This differs from batch gradient descent that it only uses one sample to estimate the loss and gradient**\n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = (h^{(i)}-y^{(i)})x_j$$\n",
    "4. Update the theta\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 4: Mini-Batch Gradient Descent\n",
    "\n",
    "The gradient descent has the following steps:\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict and calculate the loss\n",
    "3. Calculate the gradient based on the loss\n",
    "    - **This differs from batch gradient descent that it only uses a subset of samples to estimate the loss and gradient**\n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = \\sum_{i=start}^{batch}(h^{(i)}-y^{(i)})x_j$$\n",
    "    where start is a randomized number within the range of $m$ and batch is a predefined batch size, typically around 100 to 500\n",
    "4. Update the theta\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tol\n",
    "\n",
    "I will not implement this, but leave to your exercise.  Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === Task ===\n",
    "\n",
    "1. Implement early stopping in which if the absolute difference between old loss and new loss does not exceed certain threshold, we abort the learning.\n",
    "\n",
    "2. Implement options for stochastic gradient descent in which we use only one sample for training.  Make sure that sample does not repeat unless all samples are read at least once already.\n",
    "\n",
    "3. Add options for mini-batch gradient descent.\n",
    "\n",
    "3. Put everything into class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
