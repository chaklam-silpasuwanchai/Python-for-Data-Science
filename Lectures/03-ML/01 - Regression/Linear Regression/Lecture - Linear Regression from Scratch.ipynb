{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Linear Regression from Scratch\n",
    "\n",
    "### Readings: \n",
    "- [GERON] Ch4\n",
    "- [VANDER] Ch5\n",
    "- [HASTIE] Ch3\n",
    "- https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Regression is a supervised algorithm to make prediction based on continous y values.  \n",
    "\n",
    "For example, given the following data:\n",
    "\n",
    "| | Egg price  | Gold price    | Oil price   | GDP   |\n",
    "|---:|:-------------|:-----------|:------|:------|\n",
    "| 1 | 3  | 100       | 4   | 21   |\n",
    "| 2 | 4  | 500    | 7   | 43     |\n",
    "\n",
    "We want to use egg price, gold price and oil price to predict GDP.  We called egg price, gold price, oil price **features** or $\\mathbf{X}$. We called what we want to predict **labels** or **targets** or $\\mathbf{y}$.  Each row is called **sample**.  \n",
    "\n",
    "### Course Notations and Terms\n",
    "\n",
    "We shall use the following notations in our course.  \n",
    "\n",
    "- $x_j^{(i)}$ represents the i-th sample, and j-th feature. For example, $x_1^{(1)}$ denote egg price of the first sample (i.e., 100), $x_2^{(1)}$ for gold price of the first sample (i.e., 4), and $x_3^{(1)}$ for oil price of the first sample (i.e., 21).  \n",
    "\n",
    "- Bold captial $\\mathbf{X}$ denotes the whole **matrix** of features with $m$ rows of samples and $m$ columns of features.  The **shape** of $X$ is $(m, n)$.  \n",
    "\n",
    "- Bold lowercase $\\mathbf{x}$ denotes the single **vector** (i.e., column) of feature.\n",
    "\n",
    "- $y^{(i)}$ represents the **targets/labels** of the i-th sample, and $\\mathbf{y}$ refers to the whole **vector** of targets with **shape** of $(m, )$\n",
    "\n",
    "\n",
    "### Hypothesis Function\n",
    "\n",
    "**Hypothesis function** maps given input $\\mathbf{X}$ to predicted $\\mathbf{y}$.  We must **learn**/**train** this function.  To differentiate between actual and predicted $\\mathbf{y}$, we commonly called predicted $\\mathbf{y}$ as $\\hat{\\mathbf{y}}$ (read as yhat).\n",
    "\n",
    "For linear regression, the hypothesis function (denoted as $h_{\\theta}(x)$ which means $h$ depends on $x$ parametized by $\\theta$ is defined as followed.  \n",
    "\n",
    "\\begin{align*}\n",
    "h_\\theta(x) &= \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\cdots + \\theta_nx_n \\tag{A} \\\\\n",
    "&= \\sum_{i=0}^n \\theta_ix_i  \\tag{B} \\\\\n",
    "&= \\boldsymbol{\\theta}^T \\mathbf{x} \\tag{C} \\\\\n",
    "\\mathbf{h} &= \\mathbf{X}\\boldsymbol{\\theta} \\tag{D}\n",
    "\\end{align*}\n",
    "\n",
    "Here $\\theta$ are called **parameters** or **weights** or **coefficients** that parameterize the linear mappings from $\\mathbf{X}$ -> $\\mathbf{y}$.  Also, we commonly don't write equations in the (A) form.  We called (B) form as the **summation** form, (C) as the **vectorized** form, and (D) as the **matrix** form.  We like to write as (D) because it's easy to implement.\n",
    "\n",
    "The resulting hypothesis function is called **model**.  The process is called **training** the model.  The latter process of testing the model on test set is called **inference**.\n",
    "\n",
    "### How to find the best $\\theta$ ==> Gradient Descent\n",
    "\n",
    "How do we learn the best parameters $\\theta$?  \n",
    "\n",
    "First, we must define a **loss/objective function** (denoted as $J$) that measures, for a given $\\theta$, how close $h(\\mathbf{x}^{(i)})$ are to the corresponding $\\mathbf{y}^{(i)}$.  :\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "We want to choose $\\theta$ so as to minimize $J(\\theta)$.  Such process is called **optimization**.\n",
    "\n",
    "$$\\theta^* = \\argmin_\\theta J(\\theta)$$\n",
    "\n",
    "One very successful optimization algorithm is called **gradient descent** algorithm, which is based on updating theta based on the **derivatives** (we also called **gradient**).   **Why gradient descent works?**  \n",
    "\n",
    "This figure illustrates why:\n",
    "\n",
    "<img width=\"400\" src = \"figures/gradient.png\">\n",
    "\n",
    "### Formal Definition\n",
    "\n",
    "We start with some random $\\theta$, and repeatedly performs the update:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    "\n",
    " \n",
    "This update is simultaneously performed for all values of $j=0, 1, \\cdots, n$ (if you forget, $j$ here refers to each feature :-).  Here, $\\alpha$ is called the **learning rate**, ranging from 0 to 1.  Commonly, we tried 0.001 as default, and this value must be manually handpicked.  Any parameters such as learning rate are called **hyperparameters**.\n",
    "\n",
    "In order to implement this algorithm, we have to find the **partial derivative of the loss function in respect to each $\\theta_j$**.  Let's try the partial derivative of our loss function in respect to $\\theta_j$.  Also, let's first work it out for only one training example first as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial \\theta_j} &= \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}(h_\\theta(x) - y)^2 \\\\\n",
    "&= 2 * \\frac{1}{2} (h_\\theta(x) - y) * \\frac{\\partial}{\\partial \\theta_j} (h_\\theta(x) - y) \\\\\n",
    "&= 2 * \\frac{1}{2} (h_\\theta(x) - y) * \\frac{\\partial}{\\partial \\theta_j} \\big(\\sum_{i=0}^n \\theta_ix_i - y\\big) \\\\\n",
    "&= (h_\\theta(x) - y)x_j \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**==>Note: If you don't understand this, don't worry.  Just know why derivatives can help you find optimum**\n",
    "\n",
    "<!-- This rule has several properties that seem natural and intuitive. For instance, the magnitude of the update is proportional to the **error** term $h_\\theta(x) - y$; thus, for instance, if we are encountering a training example on which our prediction nearly matches the actual value of $y^{(i)}$, then we find that there is little need to change the parameters; in contrast, a larger change to the parameters will be made if our prediction has a large error (i.e., if it is very far from $y^{(i)}$).\n",
    " -->\n",
    "To modify the update rule for whole training example, we revise the update rule to include the summation as\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * \\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\tag{for every $j$}$$  or\n",
    "\n",
    "$$\\theta = \\theta - \\alpha * \\mathbf{X}^\\top (\\mathbf{h} - \\mathbf{y})$$\n",
    "\n",
    "Since this gradient descent calculates gradient using every example in the entire training set, we called this as **batch gradient descent**.\n",
    "\n",
    "Sometimes, performing batch gradient descent can be slow, thus we can use **stochastic gradient descent** which refers to looking at only one training example, where we can pick with or without replacement.  Here, **without replacement** refers to the process in which no same sample is used in the same **epoch**.  Here epoch means one  iteration which the whole training set is being exhausted.  Thus, in without replacement, we simply loop from $i =1$ to $m$ for one epoch.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha * ((h_\\theta(x)^{(i)}-y^{(i)})x_j^{(i)}) \\tag{for every $j$}$$\n",
    "\n",
    "Although **stochastic gradient descent** may be faster, it rarely converges to the optimum given its randomness.  A middle ground is **mini-batch gradient descent** which can be expressed as\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * \\sum_{i=start}^{batchsize}(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\tag{for every $j$}$$\n",
    "\n",
    "Similarly, we can do this with or without replacement.  In without replacement, we simply chop evenly and exhaust the whole training set for one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The gradient descent has the following steps:\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{y}$ and $\\mathbf{w}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{y}$ -> $(m, )$\n",
    "        - $\\mathbf{w}$ -> $(n, )$\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict and calculate the loss\n",
    "    - The loss function is the mean squared error\n",
    "    $$J = \\frac{(\\mathbf{h}-\\mathbf{y})^2}{2}$$\n",
    "    where $\\mathbf{h}$ is simply\n",
    "    $$ \\mathbf{h} = X\\boldsymbol{\\theta} $$\n",
    "3. Calculate the gradient based on the loss\n",
    "    - The gradient of the loss function is\n",
    "    $$\\frac{\\partial J}{\\partial \\theta_j} = X^\\top(\\mathbf{h} - \\mathbf{y})$$\n",
    "4. Update the theta with this update rule\n",
    "    $$\\theta = \\theta - \\alpha * \\mathbf{X}^\\top (\\mathbf{h} - \\mathbf{y})$$\n",
    "    where $\\alpha$ is a typical learning rate range between 0 and 1\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get our hands dirty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "#### 1.1 Get your X and y in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's load some diabetes data \n",
    "# as our regression case study\n",
    "from sklearn.datasets import load_diabetes\n",
    "# type - Bunch\n",
    "# Bunch - dictionary of numpy data\n",
    "# diabetes.feature_names\n",
    "# print(diabetes)\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.data\n",
    "X.shape #number of samples, number of features\n",
    "\n",
    "m = X.shape[0]  #number of samples\n",
    "n = X.shape[1]  #number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in X is the same as number of rows in y\n",
    "# because so we have yhat for all y\n",
    "assert m == y.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Train test split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the appropriate size for test data\n",
    "# 70/30 (small dataset); 80/20 (medium dataset); 90/10 (large dataset);\n",
    "# why large dataset, can set test size to 10, because\n",
    "# 10% of large dataset is already enough for testing accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "assert len(X_train)  == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Feature scale your data to reach faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to standardize my data so that mean is 0, variance is 1\n",
    "# average across each feature, NOT across each sample\n",
    "# Why we need to standardize\n",
    "# Because standardizing usually allows us to reach convergence faster\n",
    "# Why -> because the values are within smaller range\n",
    "# Thus, the gradients are also within limited range, and NOT go crazy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. StandardScaler.fit(X)  #this scaler (or self) knows the mean and std so now\n",
    "# it knows how to transform data\n",
    "# 2  X = StandardScaler.transform(X)  #not in place; will return something\n",
    "\n",
    "# 1. StandardScaler.fit_transform(X) -> 1 and 2 sequentially\n",
    "\n",
    "# create an object of StandardScaler\n",
    "# StandardScaler is a class\n",
    "# scaler is called instance/object\n",
    "\n",
    "# ALMOST always, feature scale your data using normalization or standardization\n",
    "# If you assume your data is gaussian, use standardization, otherwise, you do the normalization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Note: you MUST split first, before scale....if not, you will get data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Add intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of X they want\n",
    "# (number of samples, number of features) --> correct shape\n",
    "# for closed form formula\n",
    "# How about the intercept\n",
    "# w0 is OUR intercept\n",
    "# what is the shape of w -->(n+1, )\n",
    "# What is the shape of intercept --->(m, 1)\n",
    "#X = [1 2 3     @  [w0\n",
    "#     1 4 6         w1\n",
    "#     1 9 1         w2 \n",
    "#     1 10 2 ] \n",
    "\n",
    "# np.ones((shape))\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "\n",
    "# concatenate the intercept based on axis=1\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)\n",
    "\n",
    "# np.ones((shape))\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "\n",
    "# concatenate the intercept based on axis=1\n",
    "X_test = np.concatenate((intercept, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Feature Engineering (optional)\n",
    "\n",
    "It is sometimes useful to engineer new features (e.g., polynomial, kernels) so to create some non-linear relationships with your target.\n",
    "\n",
    "Here we gonna skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit your algorithm \n",
    "\n",
    "#### 1. Define your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Step 1: Prepare your data\n",
    "# X_train, X_test have intercepts that are being concatenated to the data\n",
    "# [1, features\n",
    "#  1, features....]\n",
    "\n",
    "# making sure our X_train has same sample size as y_train\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "\n",
    "# initialize our w\n",
    "# We don't have to do X.shape[1] + 1 because our X_train already has the\n",
    "# intercept\n",
    "# w = theta/beta/coefficients\n",
    "theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "# define the learning rate\n",
    "# later on, you gonna know that it should be better to make it slowly decreasing\n",
    "# once we perform a lot of iterations, we want the update to slow down, so it converges better\n",
    "alpha = 0.0001\n",
    "\n",
    "# define our max_iter\n",
    "# typical to call it epochs <---ml people likes to call it\n",
    "max_iter = 1000\n",
    "\n",
    "def h_theta(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def mse(yhat, y):\n",
    "    return ((yhat - y)**2).sum() / yhat.shape[0]\n",
    "\n",
    "def gradient(X, error):\n",
    "    return X.T @ error\n",
    "\n",
    "start = time()\n",
    "\n",
    "# define your for loop\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    # 1. yhat = X @ w\n",
    "    # prediction\n",
    "    # yhat (m, ) = (m, n) @ (n, )\n",
    "    yhat = h_theta(X_train, theta)\n",
    "\n",
    "    # 2. error = yhat - y_train\n",
    "    # error for use to calculate gradients\n",
    "    # error (m, ) = (m, ) - (m, )\n",
    "    error = yhat - y_train\n",
    "\n",
    "    # 3. grad = X.T @ error\n",
    "    # grad (n, ) = (n, m) @ (m, )\n",
    "    # grad for each feature j\n",
    "    grad = gradient(X_train, error)\n",
    "\n",
    "    # 4. w = w - alpha * grad\n",
    "    # update w\n",
    "    # w (n, ) = (n, ) - scalar * (n, )\n",
    "    theta = theta - alpha * grad\n",
    "\n",
    "time_taken = time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3414.023945698796\n",
      "Time used:  0.008391857147216797\n"
     ]
    }
   ],
   "source": [
    "# we got our lovely w\n",
    "# now it's time to check our accuracy\n",
    "# 1. Make prediction\n",
    "yhat = h_theta(X_test, theta)\n",
    "\n",
    "# 2. Calculate mean squared errors\n",
    "mse = mse(yhat, y_test)\n",
    "\n",
    "# print the mse\n",
    "print(\"MSE: \", mse)\n",
    "print(\"Time used: \", time_taken)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
