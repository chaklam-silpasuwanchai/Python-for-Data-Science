{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression from Scratch\n",
    "\n",
    "| | Egg price  | Gold price    | Oil price   | GDP   |\n",
    "|---:|:-------------|:-----------|:------|:------|\n",
    "| 1 | 3  | 100       | 4   | 21   |\n",
    "| 2 | 4  | 500    | 7   | 43     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#sample 1  $x^1$\n",
    "x1 = np.array([3, 100, 4])\n",
    "y1 = np.array([21])\n",
    "\n",
    "#what's the idea of prediction?  What is machine learning?\n",
    "#- find the weights that can bring you from x1 to y1\n",
    "\n",
    "#first sample\n",
    "#3 * w1 + 100 * w2 + 4 * w3 = 21\n",
    "#3 * 1  + 100 * 1  + 4 * 1  = 107\n",
    "#3 * 7  + 100 * 1  + 4 * -25  = 21\n",
    "\n",
    "#machine learning is trying to find the `best` weights\n",
    "\n",
    "#2nd sample\n",
    "#4 * w1 + 500 * w2 + 7 * w3   = 43\n",
    "#4 * 7  + 500 * 1  + 7 * -25  = 353 \n",
    "\n",
    "#machine learning is trying to find the `best` weights ACROSS all samples....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of terms and notations\n",
    "\n",
    "#2 samples\n",
    "#3 features - egg price, gold price, oil price\n",
    "    #features are the variables used for predicting the label\n",
    "    #factors, independent variables, predictors, X\n",
    "\n",
    "#egg price - x_1 --> always a vector,  e.g., [3, 4]\n",
    "#gold price - x_2 --> always a vector, e.g., [100, 500]\n",
    "#oil price - x_3 --> always a vector, e.g., [4, 7]\n",
    "#we call egg price + gold price + oil price - whole `feature matrix` --> \\mathbf{X}\n",
    "    \n",
    "#1 label - gdp\n",
    "    #label is the variable that we want to predict....\n",
    "    #target, outcome, y\n",
    "    #y_1 = y = a vector of labels, e.g., [21, 43]\n",
    "    \n",
    "#Tips: small and big\n",
    "# small mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math notations:\n",
    "\n",
    "- normal a -> scalar (one number)\n",
    "- bold  $\\mathbf{a}$  --> vector (a 1D numpy array)\n",
    "- bold  $\\mathbf{A}$  --> matrix (a 2D numpy array....)\n",
    "\n",
    "- $\\mathbf{x}_1^2$  --> feature 1, second sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How dot product works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([  [3, 100, 4] , [4, 500, 7]  ])\n",
    "X.shape  #(2, 3) means 2 samples = m, 3 features = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights = theta = params\n",
    "theta = np.array([7, 1, -25])\n",
    "theta.shape  #weights must be the sample shape as X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21, 353])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.dot(theta)\n",
    "#to be able to dot, the number should be same in the close pair\n",
    "#(2, 3)  @ (3, ) = (2, )\n",
    "#(4, 6)  @ (6, 1) = (4, 1)\n",
    "#(4, 6, 1) @ (1, 2) = (4, 6, 1, 2)\n",
    "X @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0] * theta[0] + X[0][1] * theta[1] + X[0][2] * theta[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for linear regression / gradient descent\n",
    "\n",
    "Step 1: Randomize your weight\n",
    "  - weight.shape (n, )\n",
    "\n",
    "Step 2: Use this inital weight to predict\n",
    "  - you will get errors\n",
    "\n",
    "Step 3: Find the derivative\n",
    "\n",
    "$\\mathbf{X}^\\top (\\mathbf{\\hat{y}} - \\mathbf{y})$\n",
    "\n",
    "Step 4: Change the weight\n",
    "\n",
    "$\\mathbf{w} = \\mathbf{w} - \\alpha * \\mathbf{X}^\\top (\\mathbf{\\hat{y}} - \\mathbf{y})$\n",
    "\n",
    "Step 5:  Repeat Step 2, 3, 4, until you either (1) reach the max iteration, or (2) your validation loss does not decrease anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load some toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "#print the shape of X and y\n",
    "X.shape, y.shape\n",
    "assert X.ndim == 2\n",
    "assert y.ndim == 1\n",
    "\n",
    "#print one row of X, and maybe try to see what it is...\n",
    "#print one row of y, and maybe try to see what it is....\n",
    "# X[0]\n",
    "# y[0]\n",
    "# diabetes.feature_names\n",
    "# label is blood glucose level.....\n",
    "\n",
    "#please help me set m and \n",
    "m = X.shape[0]  #number of samples\n",
    "n = X.shape[1]  #number of features\n",
    "\n",
    "#write an assert function to check that X and y has same amount of samples...\n",
    "assert m == y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We skip EDA and cleaning, because we are lazy; but actually this dataset is already clean..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split here\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 9999\n",
    ")\n",
    "\n",
    "#assert that X_train and y_train have the same amount of samples\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "\n",
    "#assert that X_test and y_test have the same amount of samples\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#standardize the training set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "#standardize the test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Add intercept to your X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: if your X is        [  [3, 2, 4],    [2, 6, 8]  ]\n",
    "# I want you to make it into   [  [1, 3, 2, 4], [1, 2, 6, 8]  ]\n",
    "# Why 1?  because imagine you have another weight, which let's call w0\n",
    "# this w0 is actually the intercept; so multiply with 1, will do nothing\n",
    "# so we can still use X @ theta....\n",
    "\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "intercept.shape\n",
    "\n",
    "#hint: use np.concatenate with X_train on axis=1, to add these ones to X_train\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)\n",
    "\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "intercept.shape\n",
    "\n",
    "#hint: use np.concatenate with X_test on axis=1, to add these ones to X_test\n",
    "X_test = np.concatenate((intercept, X_test), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Fitting!!! Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put everything fit()\n",
    "\n",
    "#1. randomize our theta\n",
    "#please help me create a random theta of size (X_train.shape[1], )\n",
    "theta = np.ones(X_train.shape[1])\n",
    "#why X_train.shape[1]\n",
    "\n",
    "#5. repeat 2, 3, 4\n",
    "#please put a for loop for 2, 3, 4, for 1000 times\n",
    "#set 1000 call it max_iter\n",
    "#for _ in range(max_iter):\n",
    "max_iter = 1000\n",
    "alpha = 0.0001\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def mean_squared_error(ytrue, ypred):\n",
    "    return ((ypred - ytrue) ** 2).sum() / ytrue.shape[0]\n",
    "\n",
    "def _grad(X, error):\n",
    "    return X.T @ error\n",
    "\n",
    "def fit(X_train, y_train, theta, max_iter, alpha):\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        #2. predict\n",
    "        yhat = predict(X_train, theta)  #put this into a function called predict(X_train, theta)\n",
    "\n",
    "        #2.1 can you guys compute the squared error\n",
    "        # squared_error = ((yhat - y_train) ** 2).sum()\n",
    "        #print the mean squared error, we can see whether MSE goes down eventually...\n",
    "        mse =  mean_squared_error(y_train, yhat)\n",
    "        if(i % 50 == 0):\n",
    "            print(f\"MSE: {mse}\")  \n",
    "\n",
    "        #3. get derivatives\n",
    "        deriv = _grad(X_train, yhat - y_train)\n",
    "\n",
    "        #4. update weight\n",
    "        theta = theta - alpha * deriv\n",
    "        \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 28562.951824703876\n",
      "MSE: 3897.3289014795173\n",
      "MSE: 2877.3645633448773\n",
      "MSE: 2831.24639141041\n",
      "MSE: 2827.9023866215557\n",
      "MSE: 2826.5434217394395\n",
      "MSE: 2825.3251211991583\n",
      "MSE: 2824.1524285941555\n",
      "MSE: 2823.016722214682\n",
      "MSE: 2821.91531119463\n",
      "MSE: 2820.8463667746114\n",
      "MSE: 2819.8083642041256\n",
      "MSE: 2818.79996461671\n",
      "MSE: 2817.819969874501\n",
      "MSE: 2816.867295693387\n",
      "MSE: 2815.9409519375267\n",
      "MSE: 2815.040027131533\n",
      "MSE: 2814.163676031542\n",
      "MSE: 2813.311109582284\n",
      "MSE: 2812.481586776238\n"
     ]
    }
   ],
   "source": [
    "theta = fit(X_train, y_train, theta, max_iter, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3079.246779652193"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = predict(X_test, theta)\n",
    "\n",
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
