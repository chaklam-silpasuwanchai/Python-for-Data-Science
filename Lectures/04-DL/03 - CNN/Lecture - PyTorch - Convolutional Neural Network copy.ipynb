{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## PyTorch - Convolutional Neural Network\n",
    "\n",
    "- [WEIDMAN] Ch7\n",
    "- https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last class we use linear network for classifying MNIST data.  Today we shall propose CNN (Convolutional Neural Network) as a better way for dealing with image classification.\n",
    "\n",
    "There are mainly three layers that can help dealing with images:\n",
    "\n",
    "1. Convolutional layer\n",
    "2. Max/Average pooling layer\n",
    "3. BatchNorm layer\n",
    "4. Dropout layer\n",
    "\n",
    "### 1. Convolutional Layer\n",
    "Let's say given a image of 14 x 14 pixels = 196 features like this.  Each data point is an array of numbers describing how dark each pixel is, where value range from 0 to 255.  These values can be normalized ranging from 0 to 1. For example, for the following digit (the digit 1), we could have:\n",
    "\n",
    "<img src =\"figures/one.png\" width=\"250\">\n",
    "\n",
    "It is first important to define the input shape of an image, which will be <code>(input channels, image height, image width)</code>.  If we have lots of images, the input shall be <code>(batch size, input channels, image height, image width)</code>.  For our case, if it is a grayscale image, the shape is <code>(1, 14, 14)</code>.  If it is a RGB image, it shall be <code>(3, 14, 14)</code>.  If it is a CMYK, it shall be <code>(4, 14, 14)</code>.  If I define batch size as 500 (out of many more images I have), my input is <code>(500, 4, 14, 14)</code>.  (Commonly, batch size is around few hundreds).\n",
    "\n",
    "Convolutional network works on the central concept of a convolution operation like this:\n",
    "\n",
    "<img src =\"figures/no_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "Mathematically, it looks like this:\n",
    "\n",
    "Let's say we have a 5 x 5 input image $I$ of channel 0 of batch 0:\n",
    "\n",
    "$$ I = \\begin{bmatrix}\n",
    "i_{11} & i_{12} & i_{13} & i_{14} & i_{15}\n",
    "\\\\\n",
    "i_{21} & i_{22} & i_{23} & i_{24} & i_{25}\n",
    "\\\\\n",
    "i_{31} & i_{32} & i_{33} & i_{34} & i_{35}\n",
    "\\\\\n",
    "i_{41} & i_{42} & i_{43} & i_{44} & i_{45}\n",
    "\\\\\n",
    "i_{51} & i_{52} & i_{53} & i_{54} & i_{55}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each of this pixel may represent the brightness ranging from 0 to 255.  Or if normalized, shall be 0 to 1.\n",
    "\n",
    "If we define a 3 x 3 patch which we commonly called **weights (W)** or in computer vision, we called **filters/kernels** like this (*we shall called filters in this lecture note for simplicity*) :\n",
    "\n",
    "$$ W = \\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13}\n",
    "\\\\\n",
    "w_{21} & w_{22} & w_{23}\n",
    "\\\\\n",
    "w_{31} & w_{32} & w_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let's say we are scanning the middle of the image, then the output feature would be (we'll denote this as $o_{33}$):\n",
    "\n",
    "$$o_{33} = w_{11} * i_{22} + w_{12} * i_{23} + w_{13} * i_{24} + \\\n",
    "           w_{21} * i_{32} + w_{22} * i_{32} + w_{23} * i_{34} + \\\n",
    "           w_{32} * i_{43} + w_{33} * i_{44}$$\n",
    "           \n",
    "This will result in one output feature called **feature map**.  Of course, we may add bias to it and then will be fed through an activation function.\n",
    "\n",
    "Actual feature maps look like this.  Each feature map is a output of a single training example and convolve each kernel over the sample.    In simple words, if we have $k$ filters, then we have $k$ feature maps.  They represent the activation part corresponding to the kernels.\n",
    "\n",
    "<img src =\"figures/feature-map2.png\" width=\"450\">\n",
    "\n",
    "In a convolution operation, there are 3 main hyperparameters to fine tune - (1) filter size, (2) padding, and (3) stride.\n",
    "\n",
    "#### A. Filters\n",
    "\n",
    "1. **How the filters look like?**.  It turns out that each filter actually detect the presence of certain visual pattern.  For example, this filter below detects whether there is an edge at that location of the image.  There are also other similar filters detecting corners, lines, etc.  Check out https://setosa.io/ev/image-kernels/  and try changing the values\n",
    "\n",
    "$$ w = \\begin{bmatrix}\n",
    "0 & 1 & 0\n",
    "\\\\\n",
    "1 & -4 & 1\n",
    "\\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Real filters can look like this.  They may look somewhat random at first glance, but we can see that clear structure being learned in most kernels. For example, filters 3 and 4 seem to be learning diagonal edges in opposite directions, and other capture round edges or enclosed spaces:\n",
    "\n",
    "<img src =\"figures/kernels.png\" width=\"200\">\n",
    "\n",
    "However, **it is important to note that we DON'T need to decide the filters** to use.  We can simply feed a random generated filter, and it is the job of CNN to learn these filters.   These learned filters will learn what features are most efficient for the classification process.\n",
    "\n",
    "**What is the shape of filters?**.  For each image, we can apply multiple filters, depending on how many output channels we want.  Let's say the input channel is 3, and we want the output channel to 64, then we apply a filter of size <code>(3, 64, filter width, filter height)</code>.  How do we know how many output channel to use? The answer is we don't know...we just try and see what works.  More filter allows the network to look at more patterns.\n",
    "\n",
    "**What should be the filter size?**  If we use a 3 x 3 filter, each pixel got 8 neighboring information.  On the other hand, if we we use big filter like 9 x 9, then we got 80 neighboring information.  Typical size is 3 and 5.\n",
    "\n",
    "\n",
    "#### B. Padding\n",
    "\n",
    "2. **How should we convolve the edges?**. Recall this image:\n",
    "\n",
    "<img src =\"figures/no_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "It has 4 x 4 pixels = 16 features.  But after convolution, we only got 2 x 2 pixels = 4 features left.  Is that good?  There are no correct answers here but we are quite sure that we lose some information.  One way is address this is **padding**, where we can enlarge the input image by padding the surroundings with zeros.  How much?  Padding until we get the original size or larger size, for example, like this.  The below put zero padding around which result the output features to be the same size as input features.\n",
    "\n",
    "<img src =\"figures/same_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "The below put even more padding which pad to make sure each single pixel is convoluted (full padding), which result the output features to be even large\n",
    "\n",
    "<img src =\"figures/full_padding_no_strides.gif\" width=\"150\">\n",
    "\n",
    "#### C. Strides\n",
    "\n",
    "3. **How many step we should take to slide our filter? Skip 2?** Should we shift 1 step per convolution, or 2 steps, or how many steps.  **In fact, it really depends on how detail you want it to be.  But defining bigger steps reduce the feature size and thus reduce the computation time.**  Bigger step is like human scanning picture more roughly but can reduce the computation time....whether to use it is something to be experimented though. \n",
    "\n",
    "In computer vision, we called this step as **stride**.  Example is like this:\n",
    "\n",
    "**No padding with stride of 2**\n",
    "\n",
    "<img src =\"figures/no_padding_strides.gif\" width=\"150\">\n",
    "\n",
    "**Padding with stride of 2**\n",
    "\n",
    "<img src =\"figures/padding_strides.gif\" width=\"150\">\n",
    "\n",
    "Actual image convolution can look like this (with stride 1 and no padding):\n",
    "\n",
    "<img src =\"figures/conv.gif\" width=\"400\">\n",
    "\n",
    "The convoluted image may look like this (nothing relate with the above matrix though):\n",
    "\n",
    "<img src =\"figures/convimages.png\" width=\"400\">\n",
    "\n",
    "**The formula to be used to measure the padding value to get the spatial size of the input and output volume to be the same with stride 1** is\n",
    "\n",
    "$$ \\frac{K-1}{2} $$\n",
    "\n",
    "where $K$ is the filter size.\n",
    "\n",
    "This means that if our image is size $24 * 24$, and the filter size is $3 x 3$, then our $K$ has size 3 so the padding should be $(3-1)/2 = 1$, then we need to add **a border of one pixel valued 0 around the outside of the image**, which would result in the input image of size $26 * 26$\n",
    "\n",
    "#### D. Shape\n",
    "\n",
    "4. **What would be the shape of the output matrix?**\n",
    "\n",
    "The output shape (denote as $O$) depend on the stride (denote as $S$), padding (denote as $P$), filter size (denote as $F$) as well as the input width and height (denote as $I$). $O$ can be calculated with the formula as follows:\n",
    "\n",
    "$$O = \\frac{W-F+2P}{S} + 1$$\n",
    "\n",
    "In this case (code below), if our W is 28, F is 5, P is 2, and S is 1 then the width/height is 28\n",
    "\n",
    "In conclusion, \n",
    "\n",
    "- The input will have a 4D shape of <code>(batch size, input channels, input height, input width)</code>\n",
    "\n",
    "- The output will have a 4D shape of <code>(batch size, output channels, output height, output width)</code>\n",
    "\n",
    "- The convolutional filters will have 4D shape of <code>(input channels, output channels, filter height, filter width)</code>\n",
    "\n",
    "**Note: The order does not matter and it depends on the python library you use but these four dimensions always exist in CNN.**\n",
    "\n",
    "### 2. Max/Average Pooling Layer\n",
    "\n",
    "Talking about **reducing computation time**, a common way is to perform a **pooling layer** which simply downsample the image by average a set of pixels, or by taking the maximum value.  If we define a pooling size of 2, this involves mapping each 2 x 2 pixels to one output, like this:\n",
    "\n",
    "<img src =\"figures/pooling.png\" width=\"150\">\n",
    "\n",
    "Nevertheless, pooling has a really big downsides, i.e., it basically lose a lot of information.  Compared to strides, strides simply scan less but maintain the same resolution but pooling simply reduce the resolution of the images....As Geoffrey Hinton said on Reddit AMA in 2014 - **The pooling operation used in CNN is a big mistake and the fact that it works so well is a disaster**.  In fact, in most recent CNN architectures like ResNets, it uses pooling very minimially or not at all.\n",
    "\n",
    "### 3. BatchNorm Layer\n",
    "\n",
    "Batch norm is nothing other than normalize samples within the batch.  That is, minus the mean of features within the batch.  This helps with unstable gradients in SGD. Note that the output size does not change from input size after BatchNorm.\n",
    "\n",
    "<img src =\"figures/batchnorm.png\" width=\"300\">\n",
    "\n",
    "<img src =\"figures/landscape.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### 4. Dropout Layer\n",
    "\n",
    "This is a layer of arbitrarily removing some values in your data.  By randomly removing data in each iteration, you make the neural network more robust against overfitting, because it needs to learn to fight with incomplete data.\n",
    "\n",
    "For example, say we have a vector of $x = {1, 2, 3, 4, 5}$.  Let's set $p=0.2$ which means 20\\% of data will be turn to 0.  In training mode, $x_\\text{train} = {1, 0, 3, 4, 5}$ ; do not confuse why I turn off 2 and not others, I just turn 20\\% off randomly.  In evaluation mode, we turn off dropout, but to make sure the distribution remains similar, we multiply the values by $1 - 0.2 = 0.8$, which becomes $x_\\text{inference} = {0.8, 1.6, 2.4, 3.2, 4.0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.ryerson.ca/~aharley/vis/conv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ETL: Load the MNIST dataset\n",
    "PyTorch makes the MNIST train and test datasets available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. The first time they're called, the datasets will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # Pytorch transformation to tensor\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data  = datasets.MNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loaders\n",
    "When working with images, we want relatively small batches; a batch size of 4 is not uncommon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional model\n",
    "In the previous section we used only fully connected layers, with an input layer of 784 (our flattened 28x28 images), hidden layers of 120 and 84 neurons, and an output size representing 10 possible digits.\n",
    "\n",
    "This time we'll employ two convolutional layers and two pooling layers before feeding data through fully connected hidden layers to our output. The model follows CONV/RELU/POOL/CONV/RELU/POOL/FC/RELU/FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take.</strong><br>\n",
    "\n",
    "1. Extend the base Module class:\n",
    "   \n",
    "<tt><font color=black>class ConvolutionalNetwork(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the convolutional layers with <a href='https://pytorch.org/docs/stable/nn.html#conv2d'><tt><strong>torch.nn.Conv2d()</strong></tt></a><br><br>The first layer has one input channel (the grayscale color channel). We'll assign 6 output channels for feature extraction. We'll set our kernel size to 3 to make a 3x3 filter, and set the step size to 1.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv1 = nn.Conv2d(1, 6, 3, 1)</font></tt><br>\n",
    "The second layer will take our 6 input channels and deliver 16 output channels.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv2 = nn.Conv2d(6, 16, 3, 1)</font></tt><br><br>\n",
    "\n",
    "3. Set up the fully connected layers with <a href='https://pytorch.org/docs/stable/nn.html#linear'><tt><strong>torch.nn.Linear()</strong></tt></a>.<br><br>The input size of (5x5x16) is determined by the effect of our kernels on the input image size. A 3x3 filter applied to a 28x28 image leaves a 1-pixel edge on all four sides. In one layer the size changes from 28x28 to 26x26. We could address this with zero-padding, but since an MNIST image is mostly black at the edges, we should be safe ignoring these pixels. We'll apply the kernel twice, and apply pooling layers twice, so our resulting output will be \n",
    "$\\;(((28-2)/2)-2)/2 = 5.5\\;$ which rounds down to 5 pixels per side.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc1 = nn.Linear(5\\*5\\*16, 120)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc2 = nn.Linear(120, 84)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc3 = nn.Linear(84, 10)</font></tt><br>\n",
    "See below for a more detailed look at this step.<br><br>\n",
    "\n",
    "4. Define the forward method.<br><br>Activations can be applied to the convolutions in one line using <a href='https://pytorch.org/docs/stable/nn.html#id27'><tt><strong>F.relu()</strong></tt></a> and pooling is done using <a href='https://pytorch.org/docs/stable/nn.html#maxpool2d'><tt><strong>F.max_pool2d()</strong></tt></a><br>\n",
    "<tt><font color=black>def forward(self, X):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv2(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "</font></tt>Flatten the data for the fully connected layers:<br><tt><font color=black>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = X.view(-1, 5\\*5\\*16)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.fc1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = self.fc2(X)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return F.log_softmax(X, dim=1)</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the convolutional layers</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab the first MNIST record\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break\n",
    "    \n",
    "X_train.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank-4 tensor to be passed into the model\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Run the first pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data\n",
    "x = x.view(-1, 5*5*16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the convolution output is passed into the fully connected layers.</strong></div>\n",
    "\n",
    "Now let's run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the bias terms for each layer, the total number of parameters being trained is:<br>\n",
    "\n",
    "$\\quad\\begin{align}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times120)+120+(120\\times84)+84+(84\\times10)+10 &=\\\\\n",
    "54+6+864+16+48000+120+10080+84+840+10 &= 60,074\\end{align}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 48000\n",
      "   120\n",
      " 10080\n",
      "    84\n",
      "   840\n",
      "    10\n",
      "______\n",
      " 60074\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
      "          [ 0.3062, -0.0730,  0.0673],\n",
      "          [-0.1623,  0.1958,  0.2938]]],\n",
      "\n",
      "\n",
      "        [[[-0.2445,  0.2897,  0.0624],\n",
      "          [ 0.2463,  0.0451,  0.1607],\n",
      "          [-0.0471,  0.2570,  0.0493]]],\n",
      "\n",
      "\n",
      "        [[[-0.1556,  0.0850, -0.1536],\n",
      "          [-0.0391, -0.1354,  0.2211],\n",
      "          [-0.2631, -0.1537, -0.0941]]],\n",
      "\n",
      "\n",
      "        [[[-0.2004,  0.0315, -0.3292],\n",
      "          [ 0.3010, -0.2832,  0.2573],\n",
      "          [ 0.0555, -0.1082,  0.2060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0520,  0.2693,  0.0364],\n",
      "          [-0.1051,  0.0896, -0.0904],\n",
      "          [ 0.1403,  0.2976,  0.1927]]],\n",
      "\n",
      "\n",
      "        [[[-0.1457,  0.1924,  0.0596],\n",
      "          [ 0.1693, -0.2032, -0.3300],\n",
      "          [-0.1288, -0.2557,  0.2735]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0960,  0.1381,  0.1054, -0.0058,  0.2609, -0.2368],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0086, -0.0929,  0.0420],\n",
      "          [-0.0469,  0.0417, -0.0284],\n",
      "          [ 0.1129, -0.0807, -0.0812]],\n",
      "\n",
      "         [[-0.0812,  0.1224,  0.0453],\n",
      "          [ 0.1309, -0.1123, -0.1350],\n",
      "          [-0.1065, -0.0915,  0.0551]],\n",
      "\n",
      "         [[ 0.0487,  0.1131, -0.0703],\n",
      "          [-0.0928,  0.0722, -0.0550],\n",
      "          [ 0.0826, -0.0323,  0.0778]],\n",
      "\n",
      "         [[-0.1057, -0.0687,  0.0415],\n",
      "          [ 0.0288, -0.0347,  0.0811],\n",
      "          [ 0.0925, -0.0987, -0.0727]],\n",
      "\n",
      "         [[ 0.1246, -0.0459, -0.0482],\n",
      "          [-0.1317, -0.0779,  0.0340],\n",
      "          [-0.0180, -0.0988,  0.0032]],\n",
      "\n",
      "         [[-0.0930, -0.1155, -0.0749],\n",
      "          [-0.1191, -0.0866,  0.1360],\n",
      "          [ 0.0257,  0.0419, -0.1269]]],\n",
      "\n",
      "\n",
      "        [[[-0.0894, -0.0453,  0.0213],\n",
      "          [-0.1197, -0.0586, -0.0815],\n",
      "          [ 0.0004, -0.0506, -0.0094]],\n",
      "\n",
      "         [[-0.0922, -0.0934, -0.0794],\n",
      "          [-0.0466, -0.1074,  0.1141],\n",
      "          [-0.0270,  0.1171,  0.0424]],\n",
      "\n",
      "         [[-0.1152,  0.0942, -0.0374],\n",
      "          [-0.0522, -0.1130, -0.1353],\n",
      "          [ 0.0389, -0.0297,  0.0530]],\n",
      "\n",
      "         [[-0.1117,  0.1010, -0.0999],\n",
      "          [-0.0235,  0.0284,  0.0703],\n",
      "          [ 0.1099,  0.1240, -0.1079]],\n",
      "\n",
      "         [[ 0.0342, -0.0585, -0.0149],\n",
      "          [-0.1019,  0.1240, -0.0999],\n",
      "          [ 0.0727,  0.0478,  0.0442]],\n",
      "\n",
      "         [[-0.0736,  0.1237,  0.0299],\n",
      "          [ 0.0175, -0.1199,  0.0571],\n",
      "          [-0.0204, -0.0623,  0.1169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303, -0.0753, -0.0689],\n",
      "          [-0.0065,  0.0760, -0.0348],\n",
      "          [-0.0776, -0.0466, -0.1017]],\n",
      "\n",
      "         [[ 0.0485,  0.1053, -0.1281],\n",
      "          [ 0.0316,  0.0703,  0.0247],\n",
      "          [-0.0485,  0.0710,  0.0715]],\n",
      "\n",
      "         [[ 0.0509, -0.0239, -0.0360],\n",
      "          [ 0.0146, -0.0240, -0.0406],\n",
      "          [ 0.0870,  0.1169, -0.0135]],\n",
      "\n",
      "         [[-0.0305,  0.0020, -0.0081],\n",
      "          [ 0.0327,  0.0381, -0.1236],\n",
      "          [-0.0502,  0.1146,  0.0530]],\n",
      "\n",
      "         [[-0.0068, -0.0820, -0.0833],\n",
      "          [-0.1219, -0.0444,  0.0460],\n",
      "          [ 0.0868,  0.0628, -0.1203]],\n",
      "\n",
      "         [[-0.0818, -0.0215,  0.1316],\n",
      "          [ 0.0197, -0.0352,  0.0563],\n",
      "          [-0.0518, -0.0881,  0.0993]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619, -0.0273, -0.1354],\n",
      "          [ 0.0911,  0.1031,  0.0496],\n",
      "          [-0.0949, -0.1343, -0.1105]],\n",
      "\n",
      "         [[ 0.1015,  0.0653,  0.1145],\n",
      "          [ 0.0713,  0.0344, -0.0013],\n",
      "          [-0.1035, -0.1166, -0.1273]],\n",
      "\n",
      "         [[ 0.0557, -0.0668, -0.0274],\n",
      "          [-0.0783, -0.0248, -0.0958],\n",
      "          [-0.0889,  0.0451, -0.0404]],\n",
      "\n",
      "         [[ 0.0840, -0.0437, -0.0998],\n",
      "          [-0.0240, -0.0660, -0.0416],\n",
      "          [-0.1296,  0.0761, -0.0947]],\n",
      "\n",
      "         [[ 0.0684,  0.0618,  0.0972],\n",
      "          [-0.1044,  0.0979, -0.0643],\n",
      "          [ 0.0505,  0.1278, -0.0192]],\n",
      "\n",
      "         [[-0.0011, -0.0313, -0.1136],\n",
      "          [ 0.0653, -0.1351,  0.0845],\n",
      "          [ 0.1018,  0.1287, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.1118,  0.0306,  0.0752],\n",
      "          [-0.1354, -0.0309, -0.0816],\n",
      "          [-0.0119, -0.0670, -0.0556]],\n",
      "\n",
      "         [[-0.0432, -0.1293,  0.1117],\n",
      "          [ 0.1141, -0.0213, -0.0155],\n",
      "          [-0.0555, -0.1229, -0.1324]],\n",
      "\n",
      "         [[ 0.0506, -0.0747, -0.0875],\n",
      "          [-0.0106, -0.0453, -0.0440],\n",
      "          [ 0.0044, -0.0289, -0.0469]],\n",
      "\n",
      "         [[-0.0652, -0.1107,  0.1141],\n",
      "          [-0.0545,  0.0361, -0.0472],\n",
      "          [ 0.0111,  0.1269,  0.0627]],\n",
      "\n",
      "         [[-0.1179,  0.0540,  0.1292],\n",
      "          [ 0.0358,  0.0912,  0.1342],\n",
      "          [-0.0209,  0.0282, -0.0946]],\n",
      "\n",
      "         [[-0.0280,  0.1008,  0.0698],\n",
      "          [-0.0861, -0.1091, -0.0930],\n",
      "          [-0.1343, -0.1050, -0.0337]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0918,  0.0228, -0.1035],\n",
      "          [-0.1092,  0.0677, -0.1012],\n",
      "          [-0.0168,  0.0653, -0.0630]],\n",
      "\n",
      "         [[-0.0148, -0.0118, -0.0322],\n",
      "          [-0.0690, -0.1213, -0.1100],\n",
      "          [-0.0729,  0.1314, -0.0657]],\n",
      "\n",
      "         [[-0.0914,  0.0330,  0.0375],\n",
      "          [ 0.0746,  0.1034,  0.0758],\n",
      "          [-0.1349,  0.0121,  0.0824]],\n",
      "\n",
      "         [[-0.0126, -0.0802,  0.1297],\n",
      "          [-0.0509, -0.0775, -0.1227],\n",
      "          [ 0.0061,  0.0603,  0.0301]],\n",
      "\n",
      "         [[ 0.0269, -0.1032, -0.1271],\n",
      "          [ 0.0024,  0.1241,  0.0785],\n",
      "          [-0.0792, -0.0177, -0.1003]],\n",
      "\n",
      "         [[-0.0656,  0.0246,  0.0741],\n",
      "          [ 0.1127, -0.1249,  0.0910],\n",
      "          [-0.0960,  0.0510,  0.1152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019,  0.1238, -0.1159],\n",
      "          [-0.0520,  0.0794, -0.0296],\n",
      "          [-0.0279, -0.0567,  0.0938]],\n",
      "\n",
      "         [[ 0.0667,  0.0436, -0.0765],\n",
      "          [-0.1105,  0.0147,  0.0403],\n",
      "          [-0.0628, -0.0381,  0.0919]],\n",
      "\n",
      "         [[ 0.0108,  0.0061, -0.0335],\n",
      "          [-0.1232, -0.1280, -0.0650],\n",
      "          [-0.0692,  0.0424, -0.0396]],\n",
      "\n",
      "         [[-0.0532,  0.1297,  0.0474],\n",
      "          [ 0.0970, -0.0659, -0.0556],\n",
      "          [ 0.0500, -0.0907, -0.0890]],\n",
      "\n",
      "         [[-0.0066, -0.0498, -0.1020],\n",
      "          [ 0.0807,  0.1094,  0.0221],\n",
      "          [-0.0237, -0.1260, -0.0496]],\n",
      "\n",
      "         [[ 0.0346,  0.0642, -0.0172],\n",
      "          [-0.0538,  0.0758, -0.1084],\n",
      "          [ 0.0860, -0.0528,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[-0.0269,  0.0165, -0.0411],\n",
      "          [ 0.0989, -0.0035,  0.1062],\n",
      "          [ 0.1308, -0.0663, -0.0993]],\n",
      "\n",
      "         [[ 0.1092,  0.1066, -0.1039],\n",
      "          [-0.0105, -0.1342, -0.1114],\n",
      "          [ 0.0263,  0.0362,  0.0288]],\n",
      "\n",
      "         [[-0.0370,  0.1255,  0.0195],\n",
      "          [-0.0803, -0.0077,  0.0327],\n",
      "          [ 0.0477, -0.0962,  0.0510]],\n",
      "\n",
      "         [[-0.0695, -0.1131, -0.0743],\n",
      "          [ 0.1312,  0.1163,  0.1219],\n",
      "          [ 0.0799,  0.1028, -0.0182]],\n",
      "\n",
      "         [[-0.0749,  0.0680, -0.0705],\n",
      "          [-0.0918, -0.0435,  0.0286],\n",
      "          [ 0.0701, -0.0529, -0.0801]],\n",
      "\n",
      "         [[ 0.0184, -0.0802, -0.0886],\n",
      "          [ 0.0709, -0.0229,  0.1244],\n",
      "          [ 0.1324,  0.0407,  0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0021, -0.0099],\n",
      "          [ 0.0019,  0.0508,  0.1265],\n",
      "          [-0.0353, -0.0575, -0.0330]],\n",
      "\n",
      "         [[-0.0657,  0.0231,  0.1016],\n",
      "          [ 0.1064,  0.0625, -0.1001],\n",
      "          [-0.0730, -0.0299, -0.0251]],\n",
      "\n",
      "         [[ 0.0112, -0.1249,  0.0424],\n",
      "          [-0.1038, -0.0861, -0.1131],\n",
      "          [ 0.1186, -0.1289,  0.1027]],\n",
      "\n",
      "         [[-0.0046, -0.0158,  0.0851],\n",
      "          [-0.0126,  0.0853,  0.0984],\n",
      "          [-0.1181,  0.0524,  0.0257]],\n",
      "\n",
      "         [[ 0.0293,  0.0199,  0.0372],\n",
      "          [-0.0655, -0.0174,  0.1293],\n",
      "          [ 0.0914, -0.0051, -0.1280]],\n",
      "\n",
      "         [[ 0.0060, -0.0927,  0.1107],\n",
      "          [-0.0826, -0.0098, -0.0302],\n",
      "          [ 0.0242,  0.1281,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0788,  0.1056,  0.1099],\n",
      "          [-0.0470, -0.0304,  0.0656],\n",
      "          [-0.0371,  0.0637, -0.0297]],\n",
      "\n",
      "         [[-0.0923,  0.0554,  0.0209],\n",
      "          [ 0.0607,  0.1352,  0.0929],\n",
      "          [ 0.1290,  0.0073, -0.1171]],\n",
      "\n",
      "         [[-0.0955, -0.0845, -0.1199],\n",
      "          [-0.0682, -0.1253, -0.1256],\n",
      "          [-0.0813, -0.1342, -0.0835]],\n",
      "\n",
      "         [[ 0.0519,  0.1135, -0.0405],\n",
      "          [-0.0396,  0.0727, -0.0671],\n",
      "          [-0.0643,  0.0838, -0.1186]],\n",
      "\n",
      "         [[ 0.0166,  0.1202,  0.0233],\n",
      "          [ 0.0370, -0.0793, -0.0019],\n",
      "          [ 0.0075,  0.0334,  0.0529]],\n",
      "\n",
      "         [[ 0.1182, -0.1039,  0.0041],\n",
      "          [-0.0680, -0.1077, -0.0109],\n",
      "          [-0.1198,  0.0950,  0.0158]]],\n",
      "\n",
      "\n",
      "        [[[-0.0733,  0.0711, -0.1288],\n",
      "          [-0.0526, -0.0265, -0.1156],\n",
      "          [-0.0865, -0.0222,  0.1033]],\n",
      "\n",
      "         [[ 0.1314,  0.0866, -0.0813],\n",
      "          [-0.0890,  0.1188,  0.0481],\n",
      "          [ 0.0036,  0.0184, -0.1094]],\n",
      "\n",
      "         [[-0.0454,  0.1310, -0.0336],\n",
      "          [-0.0068, -0.1130, -0.0761],\n",
      "          [-0.0028, -0.0845, -0.0169]],\n",
      "\n",
      "         [[ 0.0554, -0.1331,  0.0404],\n",
      "          [-0.0900, -0.0664,  0.0522],\n",
      "          [ 0.1082, -0.0372, -0.0559]],\n",
      "\n",
      "         [[-0.1231, -0.0702, -0.1192],\n",
      "          [-0.0311,  0.0278, -0.1275],\n",
      "          [ 0.1188,  0.0854, -0.1332]],\n",
      "\n",
      "         [[-0.0650,  0.0444, -0.0280],\n",
      "          [-0.0148, -0.0614,  0.1093],\n",
      "          [-0.0761,  0.1129,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274,  0.1062, -0.0224],\n",
      "          [-0.0775, -0.0220,  0.1104],\n",
      "          [-0.1010,  0.0309, -0.1337]],\n",
      "\n",
      "         [[ 0.0713,  0.0503,  0.0058],\n",
      "          [ 0.0584,  0.0002,  0.0753],\n",
      "          [-0.1077, -0.0200,  0.0604]],\n",
      "\n",
      "         [[ 0.1355,  0.0693, -0.0990],\n",
      "          [ 0.1047, -0.0303, -0.0291],\n",
      "          [-0.1237, -0.0214,  0.0963]],\n",
      "\n",
      "         [[ 0.0190, -0.0793,  0.0419],\n",
      "          [-0.0436,  0.1242, -0.1181],\n",
      "          [-0.0430, -0.1314, -0.0536]],\n",
      "\n",
      "         [[ 0.0429,  0.1310,  0.0229],\n",
      "          [ 0.1334,  0.0266,  0.0786],\n",
      "          [ 0.1091,  0.1138, -0.0762]],\n",
      "\n",
      "         [[ 0.1251,  0.0824, -0.0636],\n",
      "          [-0.0649, -0.1141,  0.0342],\n",
      "          [-0.1103,  0.0575,  0.0430]]],\n",
      "\n",
      "\n",
      "        [[[-0.1182,  0.0371, -0.0111],\n",
      "          [ 0.0622,  0.0781, -0.1353],\n",
      "          [ 0.1248,  0.1141,  0.0541]],\n",
      "\n",
      "         [[-0.1244, -0.0486, -0.0394],\n",
      "          [-0.0350,  0.0767,  0.0495],\n",
      "          [ 0.1078, -0.0510,  0.0458]],\n",
      "\n",
      "         [[ 0.0484, -0.1133, -0.1320],\n",
      "          [-0.0706,  0.0932, -0.1281],\n",
      "          [-0.1185,  0.0762,  0.0734]],\n",
      "\n",
      "         [[ 0.1119, -0.1027, -0.0996],\n",
      "          [ 0.0698,  0.1183,  0.0814],\n",
      "          [ 0.0213,  0.0448,  0.1292]],\n",
      "\n",
      "         [[-0.0878, -0.0618,  0.0952],\n",
      "          [-0.0931, -0.0750,  0.0993],\n",
      "          [ 0.0429,  0.0440, -0.0577]],\n",
      "\n",
      "         [[-0.0019,  0.1245, -0.0817],\n",
      "          [ 0.0011,  0.0647, -0.0939],\n",
      "          [ 0.1322, -0.0680, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[-0.0368, -0.0887, -0.1335],\n",
      "          [ 0.0767,  0.0362, -0.1275],\n",
      "          [-0.0876,  0.1345,  0.0520]],\n",
      "\n",
      "         [[ 0.0546, -0.0814, -0.0597],\n",
      "          [-0.0205, -0.0249, -0.0933],\n",
      "          [ 0.0112,  0.0135, -0.0172]],\n",
      "\n",
      "         [[ 0.0189, -0.0539,  0.0354],\n",
      "          [ 0.0513, -0.0717, -0.1349],\n",
      "          [ 0.0712,  0.0325, -0.0692]],\n",
      "\n",
      "         [[ 0.1311, -0.0615,  0.0920],\n",
      "          [ 0.0690, -0.1141,  0.0878],\n",
      "          [-0.1251, -0.0754, -0.0227]],\n",
      "\n",
      "         [[-0.0917,  0.1329, -0.0273],\n",
      "          [ 0.0541, -0.1215,  0.0783],\n",
      "          [-0.0423, -0.1035,  0.0199]],\n",
      "\n",
      "         [[ 0.0659,  0.1178, -0.0831],\n",
      "          [-0.0670,  0.0262,  0.0369],\n",
      "          [ 0.0523,  0.0747, -0.0309]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0756,  0.1003, -0.0355],\n",
      "          [ 0.0968,  0.0665,  0.1200],\n",
      "          [-0.0773, -0.0672, -0.0393]],\n",
      "\n",
      "         [[ 0.0069,  0.0817, -0.0777],\n",
      "          [ 0.0681, -0.0488,  0.0822],\n",
      "          [-0.0065, -0.1192, -0.0749]],\n",
      "\n",
      "         [[-0.0985,  0.0675, -0.0913],\n",
      "          [-0.0113,  0.0294, -0.0746],\n",
      "          [ 0.0393, -0.1329, -0.0974]],\n",
      "\n",
      "         [[-0.1233, -0.0412, -0.0496],\n",
      "          [ 0.0195, -0.0252,  0.0640],\n",
      "          [ 0.1248,  0.0488, -0.0536]],\n",
      "\n",
      "         [[-0.1274,  0.0493, -0.0674],\n",
      "          [ 0.0692,  0.0910,  0.0525],\n",
      "          [ 0.1277,  0.1293,  0.0288]],\n",
      "\n",
      "         [[-0.0992,  0.1216, -0.0646],\n",
      "          [-0.0643,  0.1139,  0.1054],\n",
      "          [ 0.0411,  0.0085, -0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141,  0.1305,  0.0347],\n",
      "          [ 0.0117, -0.0283, -0.0475],\n",
      "          [ 0.0811,  0.0084,  0.0885]],\n",
      "\n",
      "         [[-0.0241,  0.0595,  0.0562],\n",
      "          [ 0.0217,  0.0855,  0.0853],\n",
      "          [ 0.1261,  0.1046, -0.0348]],\n",
      "\n",
      "         [[-0.1152,  0.0249, -0.0012],\n",
      "          [-0.0355, -0.0228,  0.0064],\n",
      "          [ 0.0993,  0.0424, -0.0483]],\n",
      "\n",
      "         [[-0.0560, -0.0337, -0.0526],\n",
      "          [ 0.1224,  0.0721,  0.1229],\n",
      "          [ 0.0004,  0.0274,  0.0472]],\n",
      "\n",
      "         [[-0.1288,  0.0122, -0.0091],\n",
      "          [-0.0763, -0.1056,  0.1205],\n",
      "          [ 0.1106,  0.0631,  0.1299]],\n",
      "\n",
      "         [[-0.0552, -0.0235,  0.0515],\n",
      "          [-0.0225, -0.0267, -0.1125],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [ 0.0366, -0.0822,  0.0049]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1327, -0.0419, -0.0429,  0.0821, -0.0500, -0.0117,  0.1271, -0.0558,\n",
      "        -0.0974, -0.0762, -0.0377, -0.0646, -0.0706,  0.0550,  0.0231, -0.0436],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.8846e-02, -1.5743e-02, -2.1102e-02,  ..., -7.6693e-05,\n",
      "          4.8436e-02, -1.9859e-02],\n",
      "        [-1.1636e-02, -2.5271e-02,  7.1948e-03,  ..., -1.7114e-02,\n",
      "         -2.9444e-02,  3.3103e-02],\n",
      "        [ 6.7186e-03,  2.0927e-02, -1.8936e-02,  ..., -4.6726e-02,\n",
      "          3.3182e-03, -1.7761e-02],\n",
      "        ...,\n",
      "        [-4.3866e-02,  3.7438e-02, -4.2277e-02,  ...,  4.5558e-02,\n",
      "          2.3612e-02, -4.4892e-02],\n",
      "        [ 1.6117e-02,  1.6008e-02,  2.6415e-02,  ..., -3.6400e-02,\n",
      "          1.4238e-02,  3.9001e-02],\n",
      "        [-1.7557e-02, -2.1580e-02,  4.0183e-02,  ...,  5.0929e-03,\n",
      "          4.3303e-02, -4.1396e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0400, -0.0132, -0.0299, -0.0310,  0.0312,  0.0441,  0.0343, -0.0473,\n",
      "        -0.0008,  0.0072,  0.0363, -0.0249, -0.0220, -0.0055, -0.0091,  0.0066,\n",
      "        -0.0191, -0.0118, -0.0330,  0.0443, -0.0144, -0.0258, -0.0401, -0.0316,\n",
      "         0.0284,  0.0334,  0.0075, -0.0444, -0.0477, -0.0182, -0.0170, -0.0190,\n",
      "        -0.0163, -0.0279, -0.0349,  0.0035, -0.0400, -0.0317, -0.0016,  0.0015,\n",
      "         0.0436, -0.0034,  0.0314, -0.0055,  0.0237, -0.0089,  0.0256,  0.0277,\n",
      "        -0.0481,  0.0012,  0.0010,  0.0096, -0.0472, -0.0495, -0.0400, -0.0047,\n",
      "         0.0345, -0.0277, -0.0216, -0.0290,  0.0261,  0.0368,  0.0033,  0.0269,\n",
      "         0.0461, -0.0069, -0.0212, -0.0286,  0.0359,  0.0303, -0.0336,  0.0286,\n",
      "         0.0226,  0.0231,  0.0172, -0.0077,  0.0228, -0.0317, -0.0057,  0.0200,\n",
      "         0.0196, -0.0247, -0.0427,  0.0248, -0.0250,  0.0274, -0.0473, -0.0432,\n",
      "         0.0465,  0.0449, -0.0165,  0.0297,  0.0328, -0.0133,  0.0391,  0.0355,\n",
      "         0.0485, -0.0063, -0.0442, -0.0260, -0.0080, -0.0207,  0.0316,  0.0417,\n",
      "         0.0384,  0.0112, -0.0234, -0.0303, -0.0059, -0.0286,  0.0399, -0.0384,\n",
      "        -0.0390, -0.0290, -0.0329, -0.0307,  0.0183, -0.0207, -0.0320,  0.0365],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0371,  0.0817,  0.0687,  ..., -0.0570,  0.0406, -0.0083],\n",
      "        [ 0.0591, -0.0907, -0.0863,  ..., -0.0754,  0.0787, -0.0542],\n",
      "        [-0.0385, -0.0518,  0.0064,  ...,  0.0870,  0.0634, -0.0167],\n",
      "        ...,\n",
      "        [-0.0752,  0.0148, -0.0138,  ...,  0.0169,  0.0578, -0.0175],\n",
      "        [ 0.0579, -0.0846, -0.0538,  ..., -0.0163,  0.0133,  0.0372],\n",
      "        [-0.0691, -0.0808,  0.0382,  ..., -0.0006, -0.0693, -0.0764]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0058,  0.0849,  0.0859, -0.0189,  0.0273, -0.0852, -0.0591,  0.0678,\n",
      "         0.0148,  0.0224,  0.0103, -0.0367,  0.0740,  0.0870,  0.0377,  0.0854,\n",
      "         0.0274,  0.0690, -0.0584,  0.0318, -0.0649, -0.0117, -0.0593,  0.0311,\n",
      "        -0.0852, -0.0268, -0.0367,  0.0592, -0.0653, -0.0452,  0.0764,  0.0387,\n",
      "         0.0709,  0.0839, -0.0556,  0.0249, -0.0682, -0.0311, -0.0149, -0.0454,\n",
      "         0.0190,  0.0133,  0.0189,  0.0501, -0.0112,  0.0732, -0.0066,  0.0625,\n",
      "         0.0711,  0.0843, -0.0440, -0.0322, -0.0702, -0.0380,  0.0840, -0.0104,\n",
      "        -0.0479, -0.0699, -0.0730, -0.0506,  0.0307, -0.0485, -0.0318, -0.0764,\n",
      "        -0.0815, -0.0529, -0.0844, -0.0059, -0.0318, -0.0430, -0.0552,  0.0333,\n",
      "         0.0385, -0.0173,  0.0355,  0.0825, -0.0293, -0.0550,  0.0566, -0.0207,\n",
      "        -0.0371,  0.0593,  0.0267, -0.0664], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0248,  0.0496,  0.1048, -0.0526,  0.0552, -0.0156,  0.0163, -0.1028,\n",
      "         -0.0987,  0.0589,  0.0010,  0.0489, -0.0655,  0.0836, -0.0392, -0.0669,\n",
      "          0.0943, -0.0640, -0.0646, -0.0934,  0.0483, -0.0124, -0.0031,  0.0337,\n",
      "         -0.0306,  0.0181, -0.0586, -0.0257,  0.0614,  0.0329,  0.0728,  0.1024,\n",
      "          0.0769, -0.0391, -0.0918, -0.0467, -0.0079,  0.1040,  0.0128, -0.0154,\n",
      "          0.0767,  0.0438,  0.0905,  0.0158, -0.0073,  0.0525, -0.0067, -0.0647,\n",
      "         -0.0306, -0.0497, -0.0082,  0.0735,  0.0210, -0.0641, -0.0340, -0.0675,\n",
      "         -0.0203, -0.0563,  0.0341, -0.0174, -0.0606,  0.0495,  0.0197,  0.0262,\n",
      "          0.0665,  0.0555, -0.0718,  0.0611, -0.0739, -0.0849,  0.1066, -0.0612,\n",
      "          0.0044,  0.0641, -0.0631, -0.0488,  0.0129, -0.0111,  0.0599,  0.0168,\n",
      "         -0.0014,  0.0162,  0.1045, -0.0783],\n",
      "        [ 0.0882,  0.0137,  0.0816,  0.0278, -0.0595,  0.1075,  0.0605, -0.0945,\n",
      "          0.0949,  0.0850,  0.0864,  0.0311,  0.0391, -0.0184,  0.0773, -0.0719,\n",
      "          0.0261,  0.0701, -0.0290,  0.0690,  0.0600,  0.0104,  0.0042, -0.0508,\n",
      "         -0.0048, -0.1056,  0.0545,  0.0531,  0.0336, -0.0486, -0.0944, -0.0654,\n",
      "          0.0298, -0.0882,  0.0780,  0.1033,  0.0648, -0.0341,  0.0122, -0.0119,\n",
      "          0.0177,  0.0067,  0.0830,  0.0863,  0.0869,  0.0604,  0.0682,  0.0734,\n",
      "          0.0846,  0.0437, -0.0695,  0.0976,  0.0220, -0.0659, -0.0099,  0.0403,\n",
      "         -0.0889, -0.0849, -0.0445,  0.0882,  0.0410,  0.0559,  0.0465,  0.0951,\n",
      "          0.0974,  0.1018,  0.0684,  0.0532,  0.0421,  0.0886, -0.1047,  0.0518,\n",
      "          0.1065,  0.0381,  0.0025, -0.0355,  0.0278, -0.0517,  0.0392, -0.0233,\n",
      "          0.0412, -0.0689, -0.0730, -0.0889],\n",
      "        [ 0.0211,  0.0628,  0.0693, -0.0847,  0.0383,  0.0297,  0.0693, -0.0705,\n",
      "         -0.0365, -0.0748,  0.0076, -0.0852,  0.0821, -0.0947,  0.0081,  0.0159,\n",
      "         -0.0058, -0.0768,  0.0460,  0.0884,  0.0024,  0.0706, -0.0973, -0.0135,\n",
      "         -0.0169,  0.0932,  0.0269, -0.0902,  0.0224,  0.0129,  0.0112,  0.0595,\n",
      "          0.0545, -0.0263,  0.0419, -0.0140, -0.0723,  0.0820,  0.0403,  0.0803,\n",
      "         -0.0726,  0.0017, -0.0765, -0.0334,  0.0872, -0.0266,  0.0411,  0.0467,\n",
      "         -0.0758,  0.0754, -0.0838,  0.0873, -0.0258, -0.1054,  0.0052,  0.1044,\n",
      "          0.0385, -0.0294,  0.0247,  0.0435, -0.0972, -0.0924, -0.0883,  0.0991,\n",
      "         -0.0663, -0.0510,  0.0565, -0.0589,  0.0159,  0.0703,  0.0290,  0.0007,\n",
      "         -0.0742, -0.0620, -0.0272,  0.1014,  0.0284,  0.0358,  0.0107,  0.0040,\n",
      "          0.0957,  0.0221,  0.0344,  0.0343],\n",
      "        [ 0.0592,  0.1049, -0.0349, -0.0202,  0.0299,  0.0612,  0.1015, -0.0460,\n",
      "          0.0150,  0.0656,  0.0492,  0.0954,  0.0042, -0.0902,  0.0111, -0.0616,\n",
      "          0.0120, -0.0602, -0.0323, -0.0048, -0.0279, -0.0516,  0.0482, -0.0748,\n",
      "          0.0679, -0.0312,  0.0778, -0.0607,  0.0754,  0.0605,  0.0722, -0.1035,\n",
      "         -0.0362, -0.0975, -0.1060, -0.0828,  0.0828, -0.0497, -0.0539, -0.0125,\n",
      "          0.0375, -0.0029, -0.0727,  0.0555,  0.0570,  0.0795,  0.0531,  0.0637,\n",
      "          0.0572,  0.0589,  0.1058, -0.0806,  0.0813, -0.0870, -0.0609, -0.0027,\n",
      "          0.0824, -0.0554,  0.0745, -0.0768, -0.0549,  0.0557,  0.0213, -0.0224,\n",
      "         -0.0928,  0.0730, -0.0739,  0.0719,  0.0562, -0.0152, -0.0026, -0.1034,\n",
      "          0.0232,  0.0055, -0.0531, -0.0987,  0.0396,  0.0292,  0.0619, -0.0272,\n",
      "         -0.1031, -0.0822, -0.0343,  0.0954],\n",
      "        [ 0.0040, -0.0493,  0.0212,  0.0647,  0.0705, -0.0557,  0.0793, -0.0454,\n",
      "         -0.0629, -0.0621, -0.0586,  0.0254,  0.0817,  0.0240, -0.0413,  0.0237,\n",
      "          0.1013, -0.0606, -0.0019, -0.0351,  0.0570, -0.0371, -0.0011, -0.0276,\n",
      "         -0.1048, -0.0766, -0.0335, -0.0390, -0.0980,  0.0408, -0.0779, -0.0918,\n",
      "          0.0603, -0.0652,  0.0758,  0.0123, -0.0990,  0.1045, -0.0989, -0.1033,\n",
      "         -0.0964,  0.0613, -0.1038, -0.0192,  0.0830, -0.0264,  0.0930, -0.0911,\n",
      "          0.0578, -0.0445, -0.0826,  0.0561, -0.0509, -0.0954,  0.0651, -0.0931,\n",
      "         -0.0746, -0.0657,  0.0456,  0.0280, -0.0925, -0.1074, -0.0916,  0.0258,\n",
      "         -0.0556, -0.0061,  0.0757, -0.0800,  0.0007, -0.0619,  0.0133,  0.1062,\n",
      "         -0.0659,  0.0780,  0.0803,  0.0844,  0.0086,  0.0840,  0.0899, -0.0879,\n",
      "         -0.0358, -0.0232,  0.0621, -0.0447],\n",
      "        [ 0.0359,  0.0852,  0.1054,  0.0382,  0.0210, -0.0368,  0.0491, -0.0443,\n",
      "          0.0771, -0.0022, -0.0886,  0.0879, -0.0399,  0.0714, -0.0201,  0.1035,\n",
      "          0.1042,  0.0694, -0.0221,  0.0005, -0.0487,  0.0003,  0.0991,  0.0182,\n",
      "          0.0800, -0.0938,  0.0539, -0.0963,  0.0380, -0.1066, -0.0198, -0.0787,\n",
      "         -0.0558,  0.1086, -0.0277,  0.0586, -0.0358, -0.0492, -0.1051, -0.0162,\n",
      "          0.1058, -0.0468, -0.0245, -0.0906, -0.1037,  0.1050,  0.0538, -0.0845,\n",
      "          0.0806, -0.0374,  0.0376, -0.0050,  0.0191, -0.1032, -0.0361, -0.0882,\n",
      "          0.1031,  0.0382,  0.0413,  0.0600, -0.0701,  0.0848,  0.0677,  0.0486,\n",
      "          0.1051,  0.0244, -0.0405,  0.0713, -0.0040, -0.0774, -0.0025, -0.0208,\n",
      "         -0.0905, -0.0729,  0.0716, -0.0087,  0.0324, -0.0742, -0.0241,  0.0251,\n",
      "          0.1058, -0.0039,  0.0158, -0.1049],\n",
      "        [-0.0628, -0.0878,  0.0763,  0.0617,  0.0888, -0.0173,  0.0895,  0.0249,\n",
      "          0.0028,  0.0626,  0.0481,  0.0865,  0.0291, -0.0398,  0.0417,  0.0020,\n",
      "          0.0213,  0.0773,  0.0729, -0.0516,  0.0983,  0.0902, -0.0495,  0.0275,\n",
      "         -0.0764, -0.0047, -0.0669,  0.1046, -0.1020, -0.0022, -0.0765, -0.0040,\n",
      "         -0.1071, -0.0907,  0.0941, -0.0012,  0.0884, -0.0856, -0.0452,  0.1071,\n",
      "         -0.0486, -0.0602,  0.0889, -0.0834,  0.0450, -0.0998,  0.0317,  0.0055,\n",
      "         -0.1032,  0.0982, -0.0634, -0.0558,  0.1079, -0.0984, -0.0051,  0.0962,\n",
      "         -0.0767, -0.0544, -0.0041, -0.0942,  0.1025, -0.0020, -0.0915, -0.0235,\n",
      "         -0.0664,  0.0918,  0.0847,  0.0366, -0.0087,  0.1066,  0.0862,  0.0393,\n",
      "         -0.0934, -0.0306, -0.0805,  0.0355,  0.0673,  0.0745, -0.0246, -0.0379,\n",
      "          0.0593,  0.0546,  0.1086, -0.0660],\n",
      "        [ 0.1021, -0.0642,  0.0284, -0.0675, -0.1070,  0.0793,  0.0111,  0.0355,\n",
      "         -0.0357, -0.0184, -0.0397, -0.0551,  0.0942, -0.0625, -0.0048, -0.0386,\n",
      "         -0.1089,  0.0570,  0.1077, -0.0330, -0.0978,  0.0119, -0.0699, -0.0238,\n",
      "         -0.0631, -0.0103,  0.0035, -0.0923, -0.0942, -0.0357,  0.0766, -0.0189,\n",
      "         -0.0281, -0.0299, -0.0730, -0.0560, -0.0871, -0.1007,  0.0981, -0.0694,\n",
      "         -0.0293,  0.0322, -0.0315,  0.0487,  0.0935,  0.0130,  0.0965, -0.0375,\n",
      "         -0.0071, -0.0246,  0.0337, -0.0683,  0.1067,  0.0162, -0.0884,  0.1023,\n",
      "         -0.0524,  0.0434, -0.0031, -0.0372, -0.0488, -0.0936,  0.0193,  0.0174,\n",
      "          0.1028,  0.0344, -0.0675,  0.0182,  0.0852,  0.0666,  0.0953, -0.0364,\n",
      "          0.0892,  0.0258,  0.0221, -0.0710, -0.0403,  0.0120, -0.1073,  0.0456,\n",
      "         -0.0709, -0.0186, -0.0657,  0.0840],\n",
      "        [-0.0155,  0.0614,  0.0309,  0.0086, -0.0071,  0.0882, -0.0411,  0.0810,\n",
      "          0.1007, -0.0145, -0.0551,  0.0885, -0.0476,  0.0442, -0.0037, -0.0530,\n",
      "          0.0212,  0.0731, -0.0790, -0.0987, -0.0694, -0.0940, -0.1004,  0.0321,\n",
      "          0.0711, -0.1020,  0.0809,  0.0850, -0.0105, -0.0428,  0.0824,  0.0646,\n",
      "         -0.0827, -0.0709,  0.0913,  0.0088, -0.0296, -0.0325,  0.1031, -0.0141,\n",
      "          0.0949,  0.0054, -0.0139, -0.0252,  0.0315,  0.0637,  0.0267,  0.0253,\n",
      "         -0.0564, -0.0872, -0.0508,  0.0945,  0.0975,  0.0177,  0.0940, -0.0738,\n",
      "         -0.0525, -0.0044, -0.0806,  0.0858, -0.0377, -0.0672,  0.1069, -0.0107,\n",
      "         -0.0811,  0.0484, -0.0447, -0.0863, -0.0419,  0.0482, -0.0742,  0.0693,\n",
      "          0.0164, -0.0786,  0.0160, -0.0936,  0.0943, -0.1089, -0.0686,  0.0901,\n",
      "         -0.0554, -0.0398,  0.0504,  0.0972],\n",
      "        [ 0.0186, -0.0742,  0.0939, -0.0619,  0.0032, -0.0398,  0.0144,  0.0391,\n",
      "          0.0971, -0.1045,  0.0616, -0.0703, -0.0124,  0.0156,  0.1049, -0.1022,\n",
      "          0.0343, -0.1026,  0.0860,  0.0336, -0.0295, -0.0593,  0.0172,  0.0724,\n",
      "          0.0898,  0.0321, -0.0963, -0.0986, -0.0019,  0.0379, -0.0537,  0.0474,\n",
      "         -0.0339,  0.0696, -0.0688,  0.0789,  0.0768, -0.0309,  0.0261,  0.0124,\n",
      "         -0.0040, -0.0936, -0.0479, -0.0150, -0.0706, -0.0253, -0.1053,  0.0656,\n",
      "          0.0729,  0.0296,  0.0949, -0.0721,  0.0266, -0.0155, -0.0430,  0.0036,\n",
      "         -0.0411, -0.0384,  0.0130, -0.0367,  0.0120, -0.0739,  0.0287, -0.0913,\n",
      "          0.0911,  0.1081,  0.0193,  0.0790, -0.0005, -0.0344,  0.0530,  0.0209,\n",
      "          0.0620, -0.0369,  0.1019,  0.0579, -0.1069,  0.0029,  0.0717, -0.0314,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.0436,  0.0081, -0.0750, -0.0623]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0363, -0.1061,  0.0859,  0.0742, -0.0242, -0.0972,  0.0560, -0.0302,\n",
      "         0.0280, -0.0756], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "This time we'll feed the data directly into the model without flattening it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.21157134  accuracy:  78.233%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.61619765  accuracy:  85.392%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.02542202  accuracy:  88.494%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.02767749  accuracy:  90.283%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.00643819  accuracy:  91.450%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.00354728  accuracy:  92.267%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.06529951  accuracy:  92.869%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.00221968  accuracy:  93.412%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00033455  accuracy:  93.837%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.00892201  accuracy:  94.195%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.03726712  accuracy:  97.717%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.31302613  accuracy:  97.700%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.19266316  accuracy:  97.761%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00095279  accuracy:  97.875%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00099270  accuracy:  97.880%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.15359043  accuracy:  97.911%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.00465962  accuracy:  97.926%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.20287080  accuracy:  97.942%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.02403117  accuracy:  97.987%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.00562875  accuracy:  97.980%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00386984  accuracy:  98.717%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00092322  accuracy:  98.608%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00036388  accuracy:  98.511%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.00017684  accuracy:  98.471%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.03143325  accuracy:  98.493%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00005292  accuracy:  98.508%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00247721  accuracy:  98.488%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00065585  accuracy:  98.471%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00127100  accuracy:  98.507%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00011644  accuracy:  98.517%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.03062764  accuracy:  98.917%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.02100378  accuracy:  98.917%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.00514422  accuracy:  98.856%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.00140927  accuracy:  98.850%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.00011928  accuracy:  98.870%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.00079771  accuracy:  98.844%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00132713  accuracy:  98.843%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.00449947  accuracy:  98.873%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00113259  accuracy:  98.898%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00009867  accuracy:  98.860%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00142467  accuracy:  99.067%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.27139300  accuracy:  98.967%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00808769  accuracy:  98.983%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00000675  accuracy:  98.996%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.00410451  accuracy:  98.953%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.00055251  accuracy:  98.983%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00038263  accuracy:  98.979%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00008446  accuracy:  99.017%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.31358677  accuracy:  99.033%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00272598  accuracy:  99.028%\n",
      "\n",
      "Duration: 283 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0081),\n",
       " tensor(0.0014),\n",
       " tensor(0.0003),\n",
       " tensor(3.3747e-05),\n",
       " tensor(3.4521e-05)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may be some overfitting of the training data, there is far less than we saw with the ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deVxU9frA8c/DIoi7uIuIuwaKIq4puWdWVprZYqU385Zt3pab7XatW7fr1nKta6Xtpb80W11TNDNzSxE3EEVFXFAQQUC27++PGblIg4wKnBl43q8XL2bO+sx3Zp4553vOeY4YY1BKKeV+PKwOQCml1OXRBK6UUm5KE7hSSrkpTeBKKeWmNIErpZSb0gSulFJuShO4cnkiEiQiRkS8rI6lKHtcrS9jPhGReSKSIiIbyyK2YtZ7WfGWFxGJFJHxVsfhLjSBlzP7BzRFRHysjsUKIjJFRD4rYZp4ERlUXjFZpA8wGAgwxnS3OhjlnjSBlyMRCQL6AgYYXs7rdrmt10quORBvjDlrdSDKfWkCL1/3ABuAj4B7C48QkaoiMl1EDopIqoisE5Gq9nF9RGS9iJwWkcMiMtY+/ILdTREZKyLrCj03IvKQiMQCsfZhb9qXcUZEtohI30LTe4rIsyISJyJp9vHNROQ/IjK9SLzfi8gkRy+yuHWIyFDgWWC0iKSLyHYH834KBALf26f5e6HRd4nIIRE5KSLPFZrHQ0Qm2+M+JSILRKRucW+CiNwgItvs7bleRDoVGhcvIk+KSJT9fZgvIr6Fxj8lIkdFJFFE/lLcOuzTNhGR70QkWUT2icj99uH3AR8Aveyv8eVi5v+LiOy277EtE5HmJbWxfZzD97HQogeJSKx9uf8RESlm/cW2q/yvW2uCvS2OisgTheb1EZFZ9nGJ9sc+hcbfZH8PztiXP7TQqpuLyK/22JeLSL2LtXOlZozRv3L6A/YBE4GuQA7QsNC4/wCRQFPAE+gN+GBLZmnAHYA34A90ts8TCYwvtIyxwLpCzw2wAqgLVLUPG2NfhhfwBHAM8LWPewrYAbQDBAi1T9sdSAQ87NPVAzIKx1/kdV5sHVOAz0pop3hgUKHnQfbX8j5Q1R7XOaCDffwkbD+MAfY2+y/wZTHLDgNOAD3s7XyvfX0+hda9EWhib7fdwAP2cUOB40AIUA34wh5X62LWtQaYDfgCnYEkYKCj98rBvDfbPy8d7O34PLDeyTZ2+D4W+kz8ANTG9tlKAoYWE0Ox7VroPfnS3hYd7csaZB//D/u8DYD6wHpgqn1cdyAVWxeSB7bPfPtCn+k4oK39vY4EXrf6u+uqf5YHUFn+sPV55gD17M/3AH+zP/YAMoFQB/M9A3xTzDIjKTmBDyghrpTz6wX2AjcVM91uYLD98cPAT5fw2guvYwqXn8ADCg3bCNxeKLaBhcY1tre1l4Nlv3s+kRQathe4ptC6xxQa9wbwnv3x3MLJxJ5kHCZwoBmQB9QoNOw14CNH75WD+ZcA9xV67oHtR7P5Fb6PBuhT6PkCYPJF3nOH7VroPWlfpK0+tD+OA4YVGnctti4jsP0QzLzIZ/r5Qs8nAksv5btWmf60C6X83AssN8actD//gv91o9TDtpUW52C+ZsUMd9bhwk9E5An7bnmqiJwGatnXX9K6Psa21Yf9/6fFrbCEdVyJY4UeZwDV7Y+bA9/Yu0ROY0s8eUBDB8toDjxxflr79M2wbXGXtJ4mXNieBy8SaxMg2RiTVmT6pheZp2icbxaKMRnb1nRTuKL3EYp/fY5iKKldi7bH+XZswoXtU3hcacVX6emBrXIgtr7s2wBPETn/4fQBaotIKLbd3SygFVC0X/gwtl1OR84CfoWeN3IwTUG5SXs/6dPAQGCnMSZfRFKwJYbz62oFRDtYzmdAtD3eDsBiRwE5sQ5nyl9eaonMw8BfjDG/Ojntq8aYVy9xHQBHsSWf8wIvMm0iUFdEahRK4oHAESfXdT7Oz4uOuML38VIU265iOyAPtvbYY38ciO11Y//fHNjpYNz5+NQV0i3w8nEzti2Xq7D1hXbGlgR/Ae4xxuRj2z2fYT/w5SkivewHfT7HdtDpNhHxEhF/EelsX+42YISI+Int3N77SoijBpCLra/SS0ReBGoWGv8BMFVE2ohNJxHxBzDGJACbsG15LzTGZF7mOo4DQSJysc/ecaBlCa+lsPeAV88f5BOR+iJyUzHTvg88ICI97K+xmohcLyI1nFjPAmCsiFwlIn7AS8VNaIw5jK3f9zUR8RXbgdL7sL2fzr6mZ0Qk2P6aaonIKPu4y34fL5Ez7fqC/fMXDIwD5tuHfwk8b5+nHvAito0AgA+BcSIy0H6gtKmItL+M+Co9TeDl415gnjHmkDHm2Pk/4B1sZ1Z4AU9i2xLfhG13+V/YDhoeAoZhO1CVjC1ph9qXOxPIxpbwPqbk5LAMW99qDLZd2iwu3AWegS1JLQfOYPuiVS00/mNsB6uK7T5xYh3/Z/9/SkS2FrOM17B9+U+LyJMlvCaAN4HvgOUikobt4FkPRxMaYzYD92Nr+xRsBwrHOrEOjDFLgFnAKvt8q0qY5Q5sfcWJwDfAS8aYFU6u6xtsn4GvROQMtq3p6+yjr/R9dJYz7boGW1v8DEwzxiy3D38F2AxEYftcb7UPwxizEVuyn4ntYOYabFvr6hKJ/UCBUiUSkQhsW1FB9r0GVUnZu1AOAN7GmFxro6m8dAtcOUVEvIHHgA80eSvlGjSBqxKJSAfgNLbTyGZZHI5Syk67UJRSyk3pFrhSSrmpcj0PvF69eiYoKKg8V6mUUm5vy5YtJ40x9YsOL9cEHhQUxObNm8tzlUop5fZExOFVv9qFopRSbkoTuFJKuSlN4Eop5aYsL2aVk5NDQkICWVlZVoeiXISvry8BAQF4e3tbHYpSLs3yBJ6QkECNGjUICgpCHN8YRFUixhhOnTpFQkICLVq0sDocpVyaU10oIvKYiESLyE6x30ZLREJF5DcR2SG222vVLGk5jmRlZeHv76/JWwEgIvj7++semVJOKDGBi0gItupt3bFVwbtBRNpgK1k52RjTEVultacuNwhN3qow/Two5RxntsA7ABuMMRn2qmNrgFuw3W9vrX2aFcDIsglRKaXc17HULF7+fiepmTmlvmxnEng0EGG/kYAfttrUzezDh9unGcWFdyopILa7Vm8Wkc1JSUmlEXOpOn36NLNnz76seYcNG8bp06cvOs2LL77IypUrL2v5Sin3dSr9HK/8sIuIf6/msw0H2XQgudTX4VQxKxG5D3gISAd2YbsB73+Bt7DdGfs74FFjzEXv+hEeHm6KXom5e/duOnTocFnBl4b4+HhuuOEGoqP/fPepvLw8PD09LYjKWrm5uXh5WXt82+rPhVKXKzUzhw9+2c/cdQfIzMljRFgAjw1sQ7O6fiXPXAwR2WKMCS863KmDmMaYD40xYcaYCGx3hYk1xuwxxgwxxnTFdvukK7nxrmUmT55MXFwcnTt35qmnniIyMpL+/ftz55130rFjRwBuvvlmunbtSnBwMHPmzCmYNygoiJMnTxIfH0+HDh24//77CQ4OZsiQIWRm2u44NnbsWL7++uuC6V966SXCwsLo2LEje/bYbiWYlJTE4MGDCQsL469//SvNmzfn5MmTFPXggw8SHh5OcHAwL730v7t5bdq0id69exMaGkr37t1JS0sjLy+PJ598ko4dO9KpUyfefvvtC2IG2Lx5M/369QNgypQpTJgwgSFDhnDPPfcQHx9P3759CQsLIywsjPXr1xes74033qBjx46EhoYWtF9YWFjB+NjYWLp27XrF741S7uTsuVz+s3offf+1irdX7aNfuwYs/9s1TBsVekXJ+2Kc2swSkQbGmBMiEgiMAHoVGuYBPI/t/nlX5OXvd7Ir8cyVLuYCVzWpyUs3Bhc7/vXXXyc6Oppt27YBEBkZycaNG4mOji44jW3u3LnUrVuXzMxMunXrxsiRI/H3v3BnIzY2li+//JL333+f2267jYULFzJmzJg/ra9evXps3bqV2bNnM23aND744ANefvllBgwYwDPPPMPSpUsv+JEo7NVXX6Vu3brk5eUxcOBAoqKiaN++PaNHj2b+/Pl069aNM2fOULVqVebMmcOBAwf4448/8PLyIjm55N23LVu2sG7dOqpWrUpGRgYrVqzA19eX2NhY7rjjDjZv3sySJUtYvHgxv//+O35+fiQnJ1O3bl1q1arFtm3b6Ny5M/PmzWPs2LElrk+piiArJ48vfj/E7Mh9nEzPZkD7Bjw+uC0hTWuV+bqd3U9eaL8pag7wkDEmxX5q4UP28YuAeWUSoQW6d+9+wTnIb731Ft988w0Ahw8fJjY29k8JvEWLFnTubLvXcNeuXYmPj3e47BEjRhRMs2jRIgDWrVtXsPyhQ4dSp04dh/MuWLCAOXPmkJuby9GjR9m1axciQuPGjenWrRsANWvazuZcuXIlDzzwQEFXSN26dUt83cOHD6dqVdutE3Nycnj44YfZtm0bnp6exMTEFCx33Lhx+Pn5XbDc8ePHM2/ePGbMmMH8+fPZuHFjietTyp3l5OXz9ZYE3vo5lqOpWfRq6c9/725H1+aOv79lwakEbozp62DYm9huelpqLralXJ6qVatW8DgyMpKVK1fy22+/4efnR79+/Ryeo+zj41Pw2NPTs6ALpbjpPD09yc213UrQmeMQBw4cYNq0aWzatIk6deowduxYsrKyMMY4PO2uuOFeXl7k59vuiFb0dRR+3TNnzqRhw4Zs376d/Px8fH19L7rckSNHFuxJdO3a9U8/cEpVFHn5hu+3JzJzZQwHT2XQJbA200eF0rt1vXKPpdLXQqlRowZpaWnFjk9NTaVOnTr4+fmxZ88eNmzYUOox9OnThwULFgCwfPlyUlJS/jTNmTNnqFatGrVq1eL48eMsWbIEgPbt25OYmMimTZsASEtLIzc3lyFDhvDee+8V/Eic70IJCgpiy5YtACxcuLDYmFJTU2ncuDEeHh58+umn5OXlATBkyBDmzp1LRkbGBcv19fXl2muv5cEHH2TcuHFX3CZKuRpjDEujj3Hdm2uZNH8bVb09+fDecBY92NuS5A2awPH39+fqq68mJCSEp57687VIQ4cOJTc3l06dOvHCCy/Qs2fPUo/hpZdeYvny5YSFhbFkyRIaN25MjRo1LpgmNDSULl26EBwczF/+8heuvvpqAKpUqcL8+fN55JFHCA0NZfDgwWRlZTF+/HgCAwPp1KkToaGhfPHFFwXreuyxx+jbt+9Fz7CZOHEiH3/8MT179iQmJqZg63zo0KEMHz6c8PBwOnfuzLRp0wrmueuuuxARhgwZUtpNpJRljDGsiUnipv/8ygOfbSE3z/D2HV346dG+DOzQ0NILz8r1npiueBqhKzh37hyenp54eXnx22+/8eCDDxYcVHUn06ZNIzU1lalTp17xsvRzoVzBxgPJTFu2l43xyTStXZXHBrVhRJemeHmW77ZvcacRWl7MSsGhQ4e47bbbyM/Pp0qVKrz//vtWh3TJbrnlFuLi4li1apXVoSh1xaISTjNteQxrY5KoX8OHf9wUzOhuzfDxcq3rQjSBu4A2bdrwxx9/WB3GFTl/Fo1S7izmeBrTl+9l2c7j1Pbz5pnr2nNPryCqVnGtxH2eJnClVKUXf/Iss1bG8O32RKpV8WLSoDbc16cFNXxduya9JnClVKWVeDqTt1fFsmBzAt6ewoSIljwQ0Yo61apYHZpTNIErpSqdpLRzzI7cx+cbDmEwjOkRyEP9W9Ogpq/VoV0STeBKqUojNSOH/66NY96v8WTn5TMyrCmPDmxDQJ2yqVVS1ir9eeCXo3r16gAkJiZy6623OpymX79+FD1lsqhZs2YVXBADzpWnVUpduvRzubz9cyx93ljF7Mg4Bl3VkBV/i+CNW0PdNnmDboFfkSZNmhRUGrwcs2bNYsyYMQV1RX766afSCq1cGGMwxuDhodsByjVl5eTx2YaDzI6MI/lsNoM6NOSJIW3p0Piy7gDpcir9N+/pp5++4IYOU6ZMYfr06aSnpzNw4MCC0q/ffvvtn+aNj48nJCQEgMzMTG6//XY6derE6NGjL6iF4qgM7FtvvUViYiL9+/enf//+wIWlXmfMmEFISAghISHMmjWrYH3Fla0t7Pvvv6dHjx506dKFQYMGcfz4cQDS09MZN25cQYnZ85fSL126lLCwMEJDQxk4cGBBOxS+yjIkJIT4+PiCGCZOnEhYWBiHDx++pDK3ffv2veAipauvvpqoqCin3y+lnJGdm89nGw5yzb9X88qPu7mqcU2+mdibD+4NrzDJG1xtC3zJZDi2o3SX2agjXPd6saNvv/12Jk2axMSJEwFbxb+lS5fi6+vLN998Q82aNTl58iQ9e/Zk+PDhxV42++677+Ln50dUVBRRUVEX1Md2VAb20UcfZcaMGaxevZp69S6so7BlyxbmzZvH77//jjGGHj16cM0111CnTh2nytb26dOHDRs2ICJ88MEHvPHGG0yfPp2pU6dSq1YtduywtXFKSgpJSUncf//9rF27lhYtWjhVdnbv3r3Mmzev4IfvUsrcjh8/no8++ohZs2YRExPDuXPn6NSpU4nrVMoZefmGxX8cYdbPMRxOzqRr8zrMGt2FXq0qZnE110rgFujSpQsnTpwgMTGRpKQk6tSpQ2BgIDk5OTz77LOsXbsWDw8Pjhw5wvHjx2nUqJHD5axdu5ZHH30UgE6dOl2QlByVgb1Y0lq3bh233HJLQf2RESNG8MsvvzB8+HCnytYmJCQwevRojh49SnZ2dkFp3JUrV/LVV18VTFenTh2+//57IiIiCqZxpuxs8+bNL6gJcyllbkeNGsXUqVP597//zdy5c7VuuCoV+fmGpTuPMWNFDPtOpBPcpCbzxobQr139Cn2TbNdK4BfZUi5Lt956K19//TXHjh3j9ttvB+Dzzz8nKSmJLVu24O3tTVBQkMMysoU5+qAUVwb2Yi5Wn8aZsrWPPPIIjz/+OMOHDycyMpIpU6YULLdojM6UnYULS88WLjt7qWVu/fz8GDx4MN9++y0LFiwo8UCvUhdjjCFybxLTlu9lZ+IZWjeozuy7whga3AgPj4qbuM+r9H3gYOtG+eqrr/j6668LzipJTU2lQYMGeHt7s3r1ag4ePHjRZURERPD5558DEB0dXdCvW1wZWCi+lG1ERASLFy8mIyODs2fP8s0339C3759KshcrNTWVpk2bAvDxxx8XDB8yZAjvvPNOwfOUlBR69erFmjVrOHDgAHBh2dmtW7cCsHXr1oLxRV1qmVuw3fzh0UcfpVu3bk5t8SvlyG9xpxj13m+M+2gTZ7JymD4qlGWTIhjWsXGlSN7galvgFgkODiYtLY2mTZvSuHFjwFYa9cYbbywom9q+ffuLLuN8HexOnTrRuXNnunfvDlxYBrZly5YFZWABJkyYwHXXXUfjxo1ZvXp1wfCwsDDGjh1bsIzx48fTpUuXYu/yU9SUKVMYNWoUTZs2pWfPngXJ9/nnn+ehhx4iJCQET09PXnrpJUaMGMGcOXMYMWIE+fn5NGjQgBUrVjBy5Eg++eQTOnfuTLdu3Wjbtq3DdRX3+gqXuc3MzKRq1aqsXLmS6tWr07VrV2rWrKl1w9Vl2Xb4NNOW7WXdvpM0rOnDKzeHcFt4M6p4Vb7tUS0nq8pdYmIi/fr1Y8+ePcWegqifC1XU7qNnmL48hpW7j1O3WhUm9mvFmJ7N8fV2zUJTpUnLySqX8Mknn/Dcc88xY8YMPX9cOWV/UjozV8byQ1Qi1X28eGJwW8b1aUF1H01f2gKqXN1zzz3cc889Voeh3EBCSgZv/RzLwq1HqOLpwYPXtGJCREtq+7lHoany4BIJvLgzFlTlVJ7desr1nEjL4j+r9vHlxsMA3NOrORP7taZ+DZ8S5qx8LE/gvr6+nDp1Cn9/f03iCmMMp06dwtfXvarCqSuXcjab99bG8fH6eHLyDLeFB/DIgDY0qV3V6tBcluUJPCAggISEBJKSkqwORbkIX19fAgICrA5DlZO0rBw+XHeAD385QHp2LjeFNmHSoLYE1atW8syVnOUJ3Nvbu+AqQKVU5ZGZnccnv8Xz3po4UjJyuDa4IY8Pbke7RjWsDs1tWJ7AlVKVS3ZuPl9tOsQ7q/ZxIu0cEW3r8+SQtnQKqG11aG5HE7hSqlzk5uWz6I8jvLkyliOnM+keVJe37+hCj5YVs9BUedAErpQqU/n5hh93HGXmyhj2J52lY9Na/HNERyLa1NMTF66QJnClVJkwxvDz7hNMXxHD7qNnaNuwOu+N6cq1wQ01cZcSTeBKqVK3ft9J/r18L38cOk1zfz9mje7MjaFN8KwkRabKiyZwpVSp2XIwhenL97I+7hSNa/ny2oiO3No1AG9PLZtQFjSBK6Wu2M7EVKYvj2HVnhP4V6vCCzdcxV09AitFoSkrOZXAReQx4H5AgPeNMbNEpDPwHuAL5AITjTEbyyxSpZTL2XcinZkrY/gx6ig1fb146tp2jO0dRDUtNFUuSmxlEQnBlry7A9nAUhH5EXgDeNkYs0REhtmf9yvDWJVSLuJwcgZv/hzLoq0J+Hp78nD/1twf0ZJaVb2tDq1SceZnsgOwwRiTASAia4BbAAOcv71zLSCxTCJUl+bEblj9T4hdDia/5OkrOWMgzxjy87WA1qVoAPwTeN1X8PQQZCOg+98Xd8eX0HpQqS7SmQQeDbwqIv5AJjAM2AxMApaJyDRst2br7WhmEZkATAAIDAwsjZiVI8n7IfJ1iFoAVapDl7vBp7rVUbms9HO5bDmYwu6jZxAR2jWsjo/21zrN28OD9o1raE3uS1E7qNQX6dQdeUTkPuAhIB3YhS2RewJrjDELReQ2YIIx5qI/L47uyKOuUOoRWPsG/PEZeHhDjwlw9STw03tNOnIq/RzvRsbx6YaD5BvD6G7NeGRAGxrW1OqHynUVd0eeS76lmoj8E0gAXgNqG2OM2M7KTzXG1LzYvJrAS1F6EqybAZs+tHWVhI+Dvk9AjUZWR+aSUjNz+OCX/cxdd4DMnDxGhAXw2MA2NKvrZ3VoSpXoim6pJiINjDEnRCQQGAH0Ah4BrgEigQFAbOmFq4qVmQLr34YN70FuJnS+E655Gmpr95QjGdm5zPs1njlr95OamcP1nRrzt0Ftad1Au5eU+3O2A2uhvQ88B3jIGJMiIvcDb4qIF5CFvZ9blZFz6fD7u7bknZUKISOh37NQr7XVkbmkrJw8vvj9ELMj93EyPZuB7Rvw+JC2BDepZXVoSpUapxK4Maavg2HrgK6lHpG6UE4WbP4QfpkBGSeh3TDo/xw0CrE6MpeUk5fP11sSeOvnWI6mZtGrpT//vbsdXZvXsTo0pUqdHkJ2VXk58MensObfkJYILfvBgBcg4E/dYArIyzd8vz2RmStjOHgqgy6BtZk+KpTeretZHZpSZUYTuKvJz4Md/weRr0FKPDTrASPmQIs/7QQpbBXvlu08zowVe4k5nk77RjX48N5wBrRvoBXvVIWnCdxVGAO7v7NdhJO0Bxp1gjv/D9oMBk1Ef2KMYW3sSaYv30tUQiot61Xj7Tu6cH3HxnhoxTtVSWgCt5oxsG8lrJoKR7dDvXYw6mPoMBw8tIKbIxsPJDNt2V42xifTtHZV3ri1EyO6NMVLK96pSkYTuJXi18HPU+HwBqjdHG5+DzrdBh56RaAjUQmnmbY8hrUxSTSo4cPUm4IZ3S2QKl6auFXlpAncCke22BL3/tVQozFcP8N26btXFasjc0kxx9OYvnwvy3Yep7afN88Oa8/dPYOoWkV/6FTlpgm8PB3fCatehb0/gp8/DHkVut0H3lWtjswlxZ88y6yVMXy7PZFqVbyYNKgN9/VpQQ1frXinFGgCLx+n4mwHJ6MXgk9N6P889HwAfGpYHZlLSjydydurYlmwOQFvT2FCREseiGhFnWq6h6JUYZrAy9Lpw7DmX7DtC/DygT5/g96PaKGpYiSlnWN25D4+//0QxhjG9Ajkof6taaCFppRySBN4WUg7Dr9Mhy3zbM+7T4C+j0P1BtbG5aJSM3L479o45v0aT3ZePiPDmvLowDYE1NFCU0pdjCbw0pSRDL++CRvnQO456DIGrvk71AqwOjKXlH4ul3nrDjDnl/2kZeVyY2gT/jaoDS3ra6EppZyhCbw0ZJ2BDe/Cb+/AuTToOAr6TQb/VlZH5pKycvL4bMNBZkfGkXw2m0EdGvLEkLZ0aHzRasRKqSI0gV+JnEzY+D6smwmZydD+BluhqYZXWR2ZS8rOzWfB5sO8s2ofx85k0ad1PZ4Y0pYugVpoSqnLoQn8cuRmw9aPYe00SD8GrQbCgOehaZjVkbmkvHzD4j+OMOvnGA4nZ9K1eR1mju5Mr1b+VoemlFvTBH4p8nIhaj6seR1OH4LAXnDrXAi62urIXFJ+vmHpzmPMWBHDvhPpBDepybyxIfRrV18LTSlVCjSBOyM/H3Yttp3LfSoWGneG62dC64FaaMoBYwyRe5OYtnwvOxPP0LpBdWbfFcbQ4EZaaEqpUqQJ/GKMgZhlsOoVOL4D6neA0Z/Z+ro1cTv0W9wppi/fy+aDKTSrW5Xpo0K5uUtTPDVxK1XqNIEXZ/8aW+JO2Ah1WsCI9223MdNCUw5tO3yaacv2sm7fSRrW9OGVm0O4LbyZFppSqgxpAi/q8CZY9Q84sBZqNoUb34TOd4Gn1t9wZPfRM8xYEcOKXcepW60Kz1/fgTE9m+PrrT90SpU1TeDnHY2C1a9CzFLwqwfXvgbhfwFvvYzbkf1J6cxcGcsPUYlU9/HiicFtGdenBdV99COlVHnRb9vJWFvi3vkN+NaCgS9C97+Cj14N6MiR05m8tTKWr7cmUMXTgwevacWEiJbU9tNCU0qVt8qbwFMO2gpNbf8SvKpC3ydthaaq1rY6Mpd0Ii2L2avj+OL3QwDc06s5E/u1pn4NH4sjU6ryqnwJ/MxR+GUabPkYxAN6PGirEli9vtWRuaSUs9n8d+1+Plp/gJw8w23hATwyoA1NamsNc6WsVnkS+NlT8OtM26Xv+bm2O+BEPAW1mlodmUtKy8ph7rp4PvhlP+nZudwU2oRJg9oSVApyHogAABU0SURBVK+a1aEppewqfgLPSoXf/gO/zYbsdOg02lZoqm4LqyNzSVk5eXzyWzzvRsaRkpHDtcENeXxwO9o10ptPKOVqKm4Czz5rK+v665uQmWK7y3v/56BBe6sjc0nZufnM33SIt1ft40TaOSLa1ufJIW3pFKDHBJRyVRUvgeeegy0f2QpNnT0BrQfbCk016Wx1ZC4pNy+fRX8c4c2VsRw5nUn3oLq8c2cY3VvoXYOUcnUVJ4Hn5cL2L2DNG5B6GJr3gdGfQmBPqyNzSfn5hp+ijzJjRQz7k87SsWkt/jmiIxFt6mmhKaXchPsn8Px82LnIVmgqOQ6ahMHwt6Blf61X4oAxhlV7TjBteQy7j56hbcPqvDemK9cGN9TErZSbcd8Ebgzs/QlWvQondkKDYLj9C2g3TBN3MdbvO8m/l+/lj0Onae7vx6zRnbkxtIkWmlLKTTmVwEXkMeB+QID3jTGzRGQ+0M4+SW3gtDGm7DuajYH9q22Fpo5sgbqtYOSHEDwCPLRwkiNbD6Uwbdle1sedonEtX14b0ZFbuwbg7antpZQ7KzGBi0gItuTdHcgGlorIj8aY0YWmmQ6kllmU5x3aAD9PhYProGYADH8bQu8ET/fdkShLOxNTmbE8hp/3nKBe9Sq8eMNV3NkjUAtNKVVBOJP5OgAbjDEZACKyBrgFeMP+XIDbgAFlFSSJ22xb3PtWQLUGcN0b0HUseOll3I4cP5PFP37YxY9RR6np68VT17ZjbO8gqmmhKaUqFGe+0dHAqyLiD2QCw4DNhcb3BY4bY2IdzSwiE4AJAIGBgZcX5R+fQsImGDQFuk+AKno1YHHy8w2PfvkH2xNO88iA1ozv25JaVbUUrlIVUYkJ3BizW0T+BawA0oHtQG6hSe4AvrzI/HOAOQDh4eHmsqLs/5ytSqBvrcuavTKZv/kwvx9I5l8jOzK622X+YCql3IJTR7GMMR8aY8KMMRFAMhALICJewAhgftmFCPjV1eTthONnsvjnT7vp1dKf28KbWR2OUqqMOXsWSgNjzAkRCcSWsHvZRw0C9hhjEsoqQOW8F7+NJjs3n9dGdNRzupWqBJw9qrXQ3geeAzxkjEmxD7+di3SfqPKzNPooy3YeZ/J17bVioFKVhFMJ3BjTt5jhY0s1GnVZUjNzeOHbnQQ3qcn4PlplUanKQs8rqwBe+2k3yWezmTe2G156cY5SlYZ+293c+riTfLXpMOP7tiCkqR7oVaoy0QTuxrJy8nh20Q6a+/sxaWBbq8NRSpUz7UJxY2/+HEv8qQy+GN+DqlX08nilKhvdAndTOxNTmbN2P7eFB9C7dT2rw1FKWUATuBvKzcvn6YVR1PGrwnPDrrI6HKWURbQLxQ3N/fUA0UfOMPuuMGr5aZ0TpSor3QJ3MwdPnWXGihgGX9WQ60IaWR2OUspCmsDdiDGGZ7/ZgbeHB1NvCtHL5ZWq5DSBu5H/25LAr/tO8fR17WlUy9fqcJRSFtME7iZOpGXx6o+76R5Ulzu7a5lYpZQmcLfx8ve7yMzO47WRHfHQmxArpdAE7hZW7DrOj1FHeXRga1rVr251OEopF6EJ3MWdycrhhcXRtG9UgwkRrawORynlQvQ8cBf3xtI9nEjL4r27u1LFS39vlVL/oxnBhW2KT+azDYcYd3ULOjerbXU4SikXowncRWXl5DF5YRQBdaryxBCtNKiU+jPtQnFR/1m9j7iks3zyl+74VdG3SSn1Z7oF7oL2HDvDu5FxjAhrSkTb+laHo5RyUZrAXUxevuHphTuoVdWbF67XSoNKqeJpAncxH6+PZ/vh07x441XUqVbF6nCUUi5ME7gLOZycwbTle+nfrj7DQ5tYHY5SysVpAncRxhieWxyNAK/c0lErDSqlSqQJ3EUs3naEtTFJ/H1oe5rWrmp1OEopN6AJ3AWcSj/HP77fRVhgbcb0bG51OEopN6EJ3AVM/WEX6edyeX1kJzy10qBSykmawC22eu8JFm9LZGK/1rRtWMPqcJRSbkQTuIXSz+Xy3KIdtGlQnYn9tdKgUurS6DXaFpq2bC9Hz2Tx9QO98fHytDocpZSb0S1wi2w9lMLHv8VzT8/mdG1ex+pwlFJuSBO4BbJz85m8MIrGNX15amh7q8NRSrkppxK4iDwmItEislNEJhUa/oiI7LUPf6PswqxY3o2MI+Z4Oq/cEkJ1H+3FUkpdnhKzh4iEAPcD3YFsYKmI/AgEADcBnYwx50SkQZlGWkHEHk/jndWxDA9twoD2Da0ORynlxpzZ/OsAbDDGZACIyBrgFiAceN0Ycw7AGHOizKKsIPLzDZMX7aCajxcv3qiVBpVSV8aZLpRoIEJE/EXEDxgGNAPaAn1F5HcRWSMi3RzNLCITRGSziGxOSkoqvcjd0Oe/H2TLwRReuP4q6lX3sTocpZSbKzGBG2N2A/8CVgBLge1ALrat9zpAT+ApYIE4qMBkjJljjAk3xoTXr195b06QeDqT15fsoW+beowIa2p1OEqpCsCpg5jGmA+NMWHGmAggGYgFEoBFxmYjkA/UK7tQ3ZcxhhcWR5Nv4J9aaVApVUqcOgVCRBoYY06ISCAwAuiFLWEPACJFpC1QBThZZpG6sR+ijvLznhM8f30HmtX1szocpVQF4ew5bAtFxB/IAR4yxqSIyFxgrohEYzs75V5jjCmrQN1Vytlspny3k9CAWoy7uoXV4SilKhCnErgxpq+DYdnAmFKPqIJ55cfdpGbm8Nn4HlppUClVqvRKzDL0S2wSC7cm8MA1rejQuKbV4SilKhhN4GUkIzuXZ7/ZQct61Xh4QGurw1FKVUB6HXcZmbkihsPJmcyf0BNfb600qJQqfboFXga2Hz7Nh+sOcGePQHq09Lc6HKVUBaUJvJTl5OXz9MIo6tfwYfJ1WmlQKVV2tAullM1Zu589x9KYc3dXavp6Wx2OUqoC0y3wUrQ/KZ03f45lWMdGDAluZHU4SqkKThN4KTlfadDXy4Mpw4OtDkcpVQloAi8lX206zMYDyTx//VU0qOFrdThKqUpAE3gpOH4mi9d+2k3vVv6MCg+wOhylVCWhCbwUvPhtNNl5+VppUClVrjSBX6Gl0UdZtvM4fxvclqB61awORylViWgCvwKpGTm88O1OgpvUZHwfrTSolCpfeh74FXhtyW6Sz2Yzb2w3vDz1t1ApVb4061ym9XEn+WrTYcb3bUFI01pWh6OUqoQ0gV+GrJw8nl20g+b+fkwa2NbqcJRSlZR2oVyGWStjiT+VwRf396BqFa00qJSyhm6BX6LoI6m8/8t+Roc3o3crvYezUso6msAvQW5ePpMXRVHHrwrPDutgdThKqUpOu1AuwdxfDxB95Ayz7wqjlp9WGlRKWUu3wJ108NRZZqyIYfBVDbkuRCsNKqWspwncCcYYnlm0A28PD6beFKKXyyulXIImcCf835YE1sedYvKw9jSqpZUGlVKuQRN4CU6kZfHqj7vpHlSXO7oFWh2OUkoV0ARegpe/20VmTh6vjeyIh4d2nSilXIcm8ItYvvMYP+44ymMD29CqfnWrw1FKqQtoAi/GmawcXvg2mvaNajAhoqXV4Sil1J/oeeDFeGPpHpLSzvHfu8Px1kqDSikXpJnJgU3xyXy24RDjrm5B52a1rQ5HKaUc0gReRFZOHk8vjCKgTlWeGKKVBpVSrsupBC4ij4lItIjsFJFJ9mFTROSIiGyz/w0r21DLx39W72N/0ln+eUtH/KpoD5NSynWVmKFEJAS4H+gOZANLReRH++iZxphpZRhfudpz7AzvRsYxIqwpEW3rWx2OUkpdlDObmB2ADcaYDAARWQPcUqZRWSAv3/D0wh3UqurNC9dfZXU4SilVIme6UKKBCBHxFxE/YBjQzD7uYRGJEpG5IlLH0cwiMkFENovI5qSkpFIKu/R9tD6e7YdP89LwYOpUq2J1OEopVaISE7gxZjfwL2AFsBTYDuQC7wKtgM7AUWB6MfPPMcaEG2PC69d3zW6Jw8kZTFu2lwHtG3Bjp8ZWh6OUUk5x6iCmMeZDY0yYMSYCSAZijTHHjTF5xph84H1sfeRuxxjDc4uj8RCYerNWGlRKuQ9nz0JpYP8fCIwAvhSRwpuqt2DranE7i7cdYW1MEn8f2p6mtataHY5SSjnN2fPkFoqIP5ADPGSMSRGRT0WkM2CAeOCvZRRjmTmVfo5/fL+LsMDajOnZ3OpwlFLqkjiVwI0xfR0Mu7v0wylf//hhF+nncvnXyE54aqVBpZSbqbRXYq7ec4JvtyXyUP/WtGlYw+pwlFLqklXKBJ5+LpfnvtlBmwbVebBfK6vDUUqpy1IprxWftmwvR89k8fUDvfHx8rQ6HKWUuiyVbgt8y8EUPv4tnnt7BdG1ucNrj5RSyi1UqgSenZvP5IVRNK7py5PXtrM6HKWUuiKVqgvl3cg4Yk+kM3dsONV9KtVLV0pVQJVmCzz2eBrvrI5leGgTBrRvaHU4Sil1xSpFAs/PN0xetIPqPl68dKNWGlRKVQyVIoF/9vtBthxM4YUbrsK/uo/V4SilVKmo8Ak88XQm/1qyh75t6nFLl6ZWh6OUUqWmQidwYwwvLI4m38A/b+molQaVUhVKhU7g30cd5ec9J3jy2nY0q+tndThKKVWqKmwCTzmbzcvf7SQ0oBZjewdZHY5SSpW6Cnsy9Cs/7iY1M4fPxvfQSoNKqQqpQm6B/xKbxMKtCTxwTSs6NK5pdThKKVUmKlwCz8jO5ZlFO2hZvxoPD2htdThKKVVmKlwXyozlMSSkZLLgr73w9dZKg0qpiqtCbYFvP3yaub8e4K4egXRvUdfqcJRSqkxVmASek5fP0wujqF/Dh6eva291OEopVeYqTBfKnLX72XMsjTl3d6Wmr7fV4SilVJmrEFvgcUnpvPlzLNd3bMyQ4EZWh6OUUuXC7RN4fr7hmUU78PXy4KXhWmlQKVV5uH0C/2rTYTYeSOb566+iQQ1fq8NRSqly49YJ/PiZLF77aTe9W/kzKjzA6nCUUqpcuW0CP19pMDsvn9dGaKVBpVTl47YJfGn0MZbvOs7jg9vS3L+a1eEopVS5c8sEnpqRw4vf7SS4SU3u69PC6nCUUsoSbnke+GtLdpN8Npt5Y7vh5emWv0FKKXXF3C77rY87yVebDnN/35aENK1ldThKKWUZt0rgWTl5PLNoB839/Zg0qI3V4SillKXcqgtl1spYDp7K4Iv7e2ilQaVUpefUFriIPCYi0SKyU0QmFRn3pIgYEalXNiHaRB9J5f1f9jM6vBm9W5XpqpRSyi2UmMBFJAS4H+gOhAI3iEgb+7hmwGDgUFkGmZuXz+RFUdStVoVnh3Uoy1UppZTbcGYLvAOwwRiTYYzJBdYAt9jHzQT+Dpgyig+AD9cdIPrIGf4xPJhaflppUCmlwLkEHg1EiIi/iPgBw4BmIjIcOGKM2X6xmUVkgohsFpHNSUlJlxVkg5o+jOoawNAQrTSolFLniTElbzyLyH3AQ0A6sAvIBHoDQ4wxqSISD4QbY05ebDnh4eFm8+bNVxy0UkpVJiKyxRgTXnS4UwcxjTEfGmPCjDERQDIQD7QAttuTdwCwVUR0E1kppcqJs2ehNLD/DwRGAJ8YYxoYY4KMMUFAAhBmjDlWZpEqpZS6gLPngS8UEX8gB3jIGJNShjEppZRyglMJ3BjTt4TxQaUSjVJKKae51aX0Siml/kcTuFJKuSlN4Eop5aY0gSullJty6kKeUluZSBJw8DJnrwdc9EIhi2hcl0bjujQa16Vx1bjgymJrboypX3RguSbwKyEimx1diWQ1jevSaFyXRuO6NK4aF5RNbNqFopRSbkoTuFJKuSl3SuBzrA6gGBrXpdG4Lo3GdWlcNS4og9jcpg9cKaXUhdxpC1wppVQhmsCVUspNuVwCF5GhIrJXRPaJyGQH431EZL59/O8iEuQicY0VkSQR2Wb/G18OMc0VkRMiEl3MeBGRt+wxR4lIWFnH5GRc/UQktVBbvVhOcTUTkdUistt+g+7HHExT7m3mZFzl3mYi4isiG0Vkuz2ulx1MU+7fRyfjKvfvY6F1e4rIHyLyg4NxpdtexhiX+QM8gTigJVAF2A5cVWSaicB79se3A/NdJK6xwDvl3F4RQBgQXcz4YcASQICewO8uElc/4AcLPl+NsdWtB6gBxDh4H8u9zZyMq9zbzN4G1e2PvYHfgZ5FprHi++hMXOX+fSy07seBLxy9X6XdXq62Bd4d2GeM2W+MyQa+Am4qMs1NwMf2x18DA0VEXCCucmeMWYvtDknFuQnbzTeMMWYDUFtEGrtAXJYwxhw1xmy1P04DdgNNi0xW7m3mZFzlzt4G6fan3va/omc9lPv30cm4LCEiAcD1wAfFTFKq7eVqCbwpcLjQ8wT+/EEumMYYkwukAv4uEBfASPtu99ci0qyMY3KGs3FboZd9F3iJiASX98rtu65dsG29FWZpm10kLrCgzezdAduAE8AKY0yx7VWO30dn4gJrvo+zgL8D+cWML9X2crUE7uiXqOgvqzPTlDZn1vk9EGSM6QSs5H+/slayoq2csRVbbYdQ4G1gcXmuXESqAwuBScaYM0VHO5ilXNqshLgsaTNjTJ4xpjO2+952F5GQIpNY0l5OxFXu30cRuQE4YYzZcrHJHAy77PZytQSeABT+pQwAEoubRkS8gFqU/e56iXEZY04ZY87Zn74PdC3jmJzhTHuWO2PMmfO7wMaYnwBvEalXHusWEW9sSfJzY8wiB5NY0mYlxWVlm9nXeRqIBIYWGWXF97HEuCz6Pl4NDBfbjd6/AgaIyGdFpinV9nK1BL4JaCMiLUSkCrZO/u+KTPMdcK/98a3AKmM/ImBlXEX6SYdj68e02nfAPfYzK3oCqcaYo1YHJSKNzvf7iUh3bJ/DU+WwXgE+BHYbY2YUM1m5t5kzcVnRZiJSX0Rq2x9XBQYBe4pMVu7fR2fisuL7aIx5xhgTYGy3mLwdW1uMKTJZqbaXszc1LhfGmFwReRhYhu3Mj7nGmJ0i8g9gszHmO2wf9E9FZB+2X67bXSSuR0VkOJBrj2tsWcclIl9iOzuhnogkAC9hO6CDMeY94CdsZ1XsAzKAcWUdk5Nx3Qo8KCK5QCZwezn8CINtC+luYIe9/xTgWSCwUGxWtJkzcVnRZo2Bj0XEE9sPxgJjzA9Wfx+djKvcv4/FKcv20kvplVLKTblaF4pSSiknaQJXSik3pQlcKaXclCZwpZRyU5rAlVLKTWkCV0opN6UJXCml3NT/A1r6AuXyHd6gAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(56517)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(  94, dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 100*train_correct[0]/(len(train_loader)*10)\n",
    "temp.numpy() # converts tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9860/10000 =  98.600%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our [784,120,84,10] ANN returned an accuracy of 97.25% after 10 epochs. And it used 105,214 parameters to our current 60,074."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 978    0    2    0    1    2    4    2   15    1]\n",
      " [   0 1132    6    0    0    0    4    3    0    0]\n",
      " [   0    0 1009    0    0    0    0    1    2    0]\n",
      " [   0    0    2 1009    0   15    0    0    5    2]\n",
      " [   0    0    1    0  965    0    3    0    0    2]\n",
      " [   0    0    0    1    0  869    4    0    2    3]\n",
      " [   1    1    0    0    1    1  942    0    0    0]\n",
      " [   1    1   11    0    1    1    0 1015    3    3]\n",
      " [   0    1    1    0    4    3    1    2  944    1]\n",
      " [   0    0    0    0   10    1    0    5    3  997]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 184,  266,  321,  340,  412,  445,  460,  497,  511,  543],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x2340bfc72b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [ 184  266  321  340  412  445  460  497  511  543  582  659]\n",
      "Label: [   8    8    2    5    5    6    5    4    4    8    8    2]\n",
      "Guess: [   3    0    7    3    3    0    9    9    8    3    2    7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a new image through the model\n",
    "We can also pass a single image through the model to obtain a prediction.\n",
    "Pick a number from 0 to 9999, assign it to \"x\", and we'll use that value to select a number from the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAF6klEQVR4nO2cb2iVVRzHPz9nQ3QTG9et0VyLmFAgLrjmNF9MZpAh2MBGeyEhgYmJBXux2QvJdyEt6NX0ZsIGaU0Kp6DuxSwkkNgm0rKxkBhlzv2BdC6EMH+9uPe52527293987t7rucDY/c+5znP+e57v5yd5zznHlFVHJllSbYFPAk4kw1wJhvgTDbAmWyAM9mAlEwWkddFZFBEbopIc7pE5RqS7DhZRPKA34DXgFtAD9Cgqr+mT15usDSFuq8AN1X1dwAR+RrYCcQ1ORAIaEVFRQpNLk6GhoYYHx+XeOWpmPws8Oe097eAjTNPEpG9wF6A8vJyent7U2hycRIMBucsT6VPnu2Te6zvUdWQqgZVNbh69eoUmvMvqZh8C1gz7X0ZcDs1OblJKib3AJUi8ryI5ANvA+fSIyu3SLpPVtWHInIA6ALygJOqeiNtynKIVP7xoaoXgAtp0pKzuDs+A5zJBjiTDXAmG+BMNsCZbIAz2YCUxsmLleHhYXp6egA4f/48ACdOnIg559SpUwA0NDRkXI9LsgE5leT+/n4Atm/fzu3bsXNVIrGThk1NTYBLcs6QE0nu7OwEYM+ePQDcvXs3WpaXlwdAWVkZALt27QKgsLDQTJ9LsgG+TnJbWxsAzc3hB+VegsvKyli1ahUAx48fB2DTpk0xdU+fPg3AxMQEACtXrsyYTpdkA3yZ5AcPHgBw6NAhAEZGRgBYv349AJcuXaKkpCSmzvj4OADHjh0D4MiRIwB0dHQAUFdXlzG9LskG+DLJ+/fvB+DOnTsALF0a/jPOnj0LQCAQoK+vD4CWlhaAaB/tJdkSl2QDfJVkb/Rw8eLFmOO1tbVAeM4C4ODBg9E5i3jk5+cDUwnPJL4y+fLlywCMjo7GHO/q6or5PZ1169YBUFxcDEB3dzcAmzdvBmDr1q2ZETsN110Y4Kskz4c3CbR27VrOnDkDgLfAcd++fTHneuUWuCQb4KskFxUVAbBxY+zi0crKSgB27NgBQH19fbTMm/70Jum9RY8rVqzIrNhpuCQb4Ksk19TUAHD16tWE68zse9vb2wFYtmxZ2nTNh0uyAb5KcjKEQiEAqqurAdi2bZu5BpdkA+ZNsoisAdqBZ4BHQEhVPxeRIuAboAIYAupV9e/MSV0YV65cAaZuxcvLy4Gpx1GWJJLkh0Cjqr4IVAPvi8hLQDPQraqVQHfkvWMW5k2yqg4Dw5HX90VkgPA3n3YCNZHT2oAfgKaMqEyCo0ePArBkSThHjY2NWdOyoD5ZRCqAl4GfgJLIB+B9EMVx6uwVkV4R6R0bG0tNrU9JeHQhIgXAt8CHqjoxc7FIPFQ1BIQAgsGg2TYx3uOm0tJSADZs2GDV9GMklGQReYqwwV+p6neRwyMiUhopLwVG49V/0klkdCHAl8CAqn42regc8A7wSeR3Z0YUJsHExAT37t0Dpha8ZJNEuotXgd1Av4hcjxz7iLC5HSLyLvAH8FZmJPqfREYXPzL7V3wBatMrJz0MDAwwODiYbRlR3B2fATk5d9Ha2hp9vWXLliwqCeOSbEBOJXlychKYeiINUFVVlS05UVySDcipJHvzFAUFBRw+fBiwXewdD5dkA3IqycuXLwfC4+TFhEuyAUnvC5dUYyJjwD/AuFmj6SfA4/qfU9W4u1iZmgwgIr2qOvceX4uYZPS77sIAZ7IB2TA5lIU208mC9Zv3yU8irrswwJlsgJnJftzQWkTWiMj3IjIgIjdE5IPI8Y9F5C8RuR75eWPO61j0yX7d0DryFL5UVa+JSCHQB7wJ1AOTqvppItexSnJ0Q2tV/RfwNrRe1KjqsKpei7y+D3irpxaElcmzbWi9YLHZZMbqKYADIvKziJwUkafnqmtlckIbWi9WZq6eAlqBF4AqwusEW+aqb2Wybze0nm31lKqOqOp/qvoI+IJwdxgXK5N9uaF1vNVT3vK0CHXAL3Ndx2TS3scbWsdbPdUgIlWEu7wh4L25LuJuqw1wd3wGOJMNcCYb4Ew2wJlsgDPZAGeyAf8DLOq+O+Kl0NMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 2019\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(test_data[x][0].reshape((28,28)), cmap=\"gist_yarg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())\n",
    "# model.eval() vs torch.no_grad()\n",
    "# https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
